#!/usr/bin/env python3
"""
æ•°æ®æ ¼å¼å¯¹é½å¤„ç†å™¨

å°†æºæ•°æ®æ ¼å¼å¯¹é½åˆ°ç›®æ ‡æ ¼å¼ï¼Œä¿ç•™æŒ‡å®šå­—æ®µ
"""

import json
import logging
from pathlib import Path
from typing import List, Dict, Any

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataFormatAligner:
    """æ•°æ®æ ¼å¼å¯¹é½å™¨"""
    
    def __init__(self):
        # ç›®æ ‡æ ¼å¼éœ€è¦ä¿ç•™çš„å­—æ®µ
        self.target_fields = {
            'function_name',
            'orm_code', 
            'caller',
            'sql_statement_list',
            'sql_types',
            'code_meta_data',
            'sql_pattern_cnt',
            'source_file'
        }
    
    def align_record(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¯¹é½å•æ¡è®°å½•çš„æ ¼å¼
        
        Args:
            record: æºè®°å½•
            
        Returns:
            å¯¹é½åçš„è®°å½•
        """
        aligned_record = {}
        
        # åªä¿ç•™ç›®æ ‡å­—æ®µ
        for field in self.target_fields:
            if field in record:
                aligned_record[field] = record[field]
            else:
                # å¦‚æœç¼ºå°‘å¿…è¦å­—æ®µï¼Œè®¾ç½®é»˜è®¤å€¼
                if field == 'caller':
                    aligned_record[field] = ""
                elif field == 'sql_statement_list':
                    aligned_record[field] = []
                elif field == 'sql_types':
                    aligned_record[field] = []
                elif field == 'code_meta_data':
                    aligned_record[field] = []
                elif field == 'sql_pattern_cnt':
                    aligned_record[field] = 0
                else:
                    aligned_record[field] = ""
        
        return aligned_record
    
    def process_file(self, source_file: str, target_file: str) -> Dict[str, Any]:
        """
        å¤„ç†æ•´ä¸ªæ–‡ä»¶
        
        Args:
            source_file: æºæ–‡ä»¶è·¯å¾„
            target_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {source_file}")
        
        # è¯»å–æºæ•°æ®
        with open(source_file, 'r', encoding='utf-8') as f:
            source_data = json.load(f)
        
        if not isinstance(source_data, list):
            raise ValueError("æºæ•°æ®å¿…é¡»æ˜¯åˆ—è¡¨æ ¼å¼")
        
        # å¯¹é½æ¯æ¡è®°å½•
        aligned_data = []
        removed_fields_stats = {}
        
        for i, record in enumerate(source_data):
            # ç»Ÿè®¡è¢«ç§»é™¤çš„å­—æ®µ
            for field in record.keys():
                if field not in self.target_fields:
                    removed_fields_stats[field] = removed_fields_stats.get(field, 0) + 1
            
            # å¯¹é½è®°å½•
            aligned_record = self.align_record(record)
            aligned_data.append(aligned_record)
        
        # ä¿å­˜å¯¹é½åçš„æ•°æ®
        target_path = Path(target_file)
        target_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(target_file, 'w', encoding='utf-8') as f:
            json.dump(aligned_data, f, ensure_ascii=False, indent=2)
        
        # ç»Ÿè®¡ç»“æœ
        result = {
            'source_file': source_file,
            'target_file': target_file,
            'total_records': len(source_data),
            'aligned_records': len(aligned_data),
            'retained_fields': list(self.target_fields),
            'removed_fields_stats': removed_fields_stats
        }
        
        logger.info(f"å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(source_data)} æ¡è®°å½•")
        logger.info(f"ç§»é™¤çš„å­—æ®µç»Ÿè®¡: {removed_fields_stats}")
        
        return result
    
    def compare_formats(self, source_file: str, target_file: str):
        """
        æ¯”è¾ƒä¸¤ä¸ªæ–‡ä»¶çš„æ ¼å¼å·®å¼‚
        
        Args:
            source_file: æºæ–‡ä»¶è·¯å¾„
            target_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„
        """
        logger.info("å¼€å§‹æ¯”è¾ƒæ–‡ä»¶æ ¼å¼...")
        
        # è¯»å–ä¸¤ä¸ªæ–‡ä»¶
        with open(source_file, 'r', encoding='utf-8') as f:
            source_data = json.load(f)
        
        with open(target_file, 'r', encoding='utf-8') as f:
            target_data = json.load(f)
        
        if not source_data or not target_data:
            logger.warning("æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•æ¯”è¾ƒ")
            return
        
        # è·å–å­—æ®µé›†åˆ
        source_fields = set(source_data[0].keys()) if source_data else set()
        target_fields = set(target_data[0].keys()) if target_data else set()
        
        # æ¯”è¾ƒå·®å¼‚
        only_in_source = source_fields - target_fields
        only_in_target = target_fields - source_fields
        common_fields = source_fields & target_fields
        
        logger.info(f"æºæ–‡ä»¶å­—æ®µæ•°: {len(source_fields)}")
        logger.info(f"ç›®æ ‡æ–‡ä»¶å­—æ®µæ•°: {len(target_fields)}")
        logger.info(f"å…±åŒå­—æ®µæ•°: {len(common_fields)}")
        logger.info(f"ä»…æºæ–‡ä»¶æœ‰çš„å­—æ®µ: {sorted(only_in_source)}")
        logger.info(f"ä»…ç›®æ ‡æ–‡ä»¶æœ‰çš„å­—æ®µ: {sorted(only_in_target)}")
        logger.info(f"å…±åŒå­—æ®µ: {sorted(common_fields)}")


def main():
    """ä¸»å‡½æ•°"""
    source_file = "workflow_output/workflow_v1/0709111.json"
    target_reference = "workflow_output/workflow_v1/final_processed_dataset.json"
    output_file = "workflow_output/workflow_v1/aligned_data.json"
    
    aligner = DataFormatAligner()
    
    try:
        # æ¯”è¾ƒæ ¼å¼å·®å¼‚
        aligner.compare_formats(source_file, target_reference)
        
        print("\n" + "="*50)
        print("å¼€å§‹æ•°æ®æ ¼å¼å¯¹é½...")
        
        # æ‰§è¡Œæ ¼å¼å¯¹é½
        result = aligner.process_file(source_file, output_file)
        
        print("\nâœ… æ•°æ®æ ¼å¼å¯¹é½å®Œæˆ!")
        print(f"ğŸ“ æºæ–‡ä»¶: {result['source_file']}")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {result['target_file']}")
        print(f"ğŸ“Š å¤„ç†è®°å½•æ•°: {result['total_records']:,}")
        print(f"ğŸ“‹ ä¿ç•™å­—æ®µ: {len(result['retained_fields'])} ä¸ª")
        print(f"ğŸ—‘ï¸  ç§»é™¤å­—æ®µç»Ÿè®¡:")
        
        for field, count in result['removed_fields_stats'].items():
            print(f"   - {field}: {count} æ¡è®°å½•")
        
        print(f"\nğŸ“„ ä¿ç•™çš„å­—æ®µåˆ—è¡¨:")
        for field in sorted(result['retained_fields']):
            print(f"   - {field}")
            
    except Exception as e:
        logger.error(f"å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main()) 