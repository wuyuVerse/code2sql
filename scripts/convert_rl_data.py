#!/usr/bin/env python3
"""
RLè®­ç»ƒæ•°æ®è½¬æ¢å¿«é€Ÿå¯åŠ¨è„šæœ¬

ç”¨äºå°†workflowå¤„ç†åçš„ORMæ•°æ®è½¬æ¢ä¸ºRLHFè®­ç»ƒæ ¼å¼ï¼ˆparquetæ–‡ä»¶ï¼‰
"""

import sys
import os
import pandas as pd
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parents[1]
sys.path.insert(0, str(project_root))

from data_processing.rl_data_converter import RLDataConverter

def show_data_sample(parquet_path: Path, num_samples: int = 3):
    """
    æ˜¾ç¤ºæ•°æ®æ ·ä¾‹
    
    Args:
        parquet_path: parquetæ–‡ä»¶è·¯å¾„
        num_samples: æ˜¾ç¤ºçš„æ ·ä¾‹æ•°é‡
    """
    print(f"\nğŸ“‹ æ•°æ®æ ·ä¾‹ ({parquet_path.name}):")
    print("=" * 80)
    
    df = pd.read_parquet(parquet_path)
    
    for i in range(min(num_samples, len(df))):
        row = df.iloc[i]
        print(f"\næ ·ä¾‹ {i+1}:")
        print("-" * 40)
        
        print(f"ğŸ¯ æ•°æ®æº: {row['data_source']}")
        print(f"ğŸ§  èƒ½åŠ›ç±»åˆ«: {row['ability']}")
        
        print(f"\nğŸ’¬ æç¤ºè¯ (prompt):")
        for j, message in enumerate(row['prompt']):
            role = message['role']
            content = message['content'][:200] + "..." if len(message['content']) > 200 else message['content']
            print(f"  [{j+1}] {role}: {content}")
        
        print(f"\nğŸ† å¥–åŠ±æ¨¡å‹é…ç½®:")
        reward_model = row['reward_model']
        print(f"  æ ·å¼: {reward_model['style']}")
        ground_truth = reward_model['ground_truth']
        if isinstance(ground_truth, str) and len(ground_truth) > 100:
            ground_truth = ground_truth[:100] + "..."
        print(f"  æ ‡å‡†ç­”æ¡ˆ: {ground_truth}")
        
        print(f"\nğŸ“Š é¢å¤–ä¿¡æ¯:")
        extra_info = row['extra_info']
        print(f"  ç´¢å¼•: {extra_info['index']}")
        print(f"  åˆ†ç»„: {extra_info['split']}")
        print(f"  å‡½æ•°å: {extra_info['function_name']}")
        print(f"  SQLç±»å‹æ•°: {extra_info['sql_pattern_cnt']}")
        
        if i < min(num_samples, len(df)) - 1:
            print("\n" + "="*60)

def show_data_format_info():
    """æ˜¾ç¤ºRLæ•°æ®æ ¼å¼è¯´æ˜"""
    print("\nğŸ“– RLæ•°æ®æ ¼å¼è¯´æ˜:")
    print("=" * 80)
    print("""
RLè®­ç»ƒæ•°æ®é‡‡ç”¨RLHF (Reinforcement Learning from Human Feedback) æ ¼å¼ï¼Œ
å­˜å‚¨ä¸ºparquetæ–‡ä»¶ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

ğŸ”¹ data_source (str): æ•°æ®æ¥æºæ ‡è¯†
   - ç”¨äºåœ¨RewardManagerä¸­é€‰æ‹©å¯¹åº”çš„å¥–åŠ±å‡½æ•°
   - æœ¬é¡¹ç›®ä¸­ä¸º: "code2sql_orm"

ğŸ”¹ prompt (list): èŠå¤©æ ¼å¼çš„æç¤ºè¯
   - æ ¼å¼: [{"role": "user", "content": "..."}]
   - æ”¯æŒå¤šè½®å¯¹è¯ï¼Œä½†æœ¬é¡¹ç›®ä¸»è¦ä½¿ç”¨å•è½®
   - å†…å®¹åŒ…å«ORMä»£ç åˆ†æè¦æ±‚å’Œä¸Šä¸‹æ–‡ä¿¡æ¯

ğŸ”¹ ability (str): ä»»åŠ¡èƒ½åŠ›ç±»åˆ«
   - ç”¨äºä»»åŠ¡åˆ†ç±»å’Œè¯„ä¼°
   - æœ¬é¡¹ç›®ä¸­ä¸º: "code_generation"

ğŸ”¹ reward_model (dict): å¥–åŠ±æ¨¡å‹é…ç½®
   - style: "rule" (åŸºäºè§„åˆ™è¯„åˆ†) æˆ– "model" (åŸºäºæ¨¡å‹è¯„åˆ†)
   - ground_truth: æ ‡å‡†ç­”æ¡ˆï¼Œç”¨äºè®¡ç®—å¥–åŠ±åˆ†æ•°
   - æœ¬é¡¹ç›®ä½¿ç”¨SQLè¯­å¥çš„JSONæ•°ç»„ä½œä¸ºæ ‡å‡†ç­”æ¡ˆ

ğŸ”¹ extra_info (dict): é¢å¤–å…ƒä¿¡æ¯
   - index: æ•°æ®ç´¢å¼•
   - split: æ•°æ®é›†åˆ’åˆ† ("train" æˆ– "val")
   - function_name, source_file, sql_pattern_cnt ç­‰è°ƒè¯•ä¿¡æ¯

è¿™ç§æ ¼å¼ä¸verlæ¡†æ¶å®Œå…¨å…¼å®¹ï¼Œå¯ç›´æ¥ç”¨äºPPOã€DPOç­‰RLç®—æ³•è®­ç»ƒã€‚
""")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ORMåˆ°SQLçš„RLè®­ç»ƒæ•°æ®è½¬æ¢...")
    
    converter = RLDataConverter()
    
    try:
        # æ‰§è¡Œè½¬æ¢
        train_path, val_path, dataset_info = converter.run_conversion(val_ratio=0.1)
        
        print(f"\nâœ… RLæ•°æ®è½¬æ¢å®Œæˆ!")
        print(f"ğŸ“ è®­ç»ƒé›†è·¯å¾„: {train_path}")
        print(f"ğŸ“ éªŒè¯é›†è·¯å¾„: {val_path}")
        print(f"ğŸ“Š è®­ç»ƒé›†æ ·æœ¬æ•°: {dataset_info['train']['num_samples']}")
        print(f"ğŸ“Š éªŒè¯é›†æ ·æœ¬æ•°: {dataset_info['val']['num_samples']}")
        print(f"ğŸ“Š æ€»æ ·æœ¬æ•°: {dataset_info['total_samples']}")
        info_file = converter.rl_data_dir / f"{dataset_info['dataset_name']}_info.json"
        print(f"ğŸ“ æ•°æ®é›†ä¿¡æ¯: {info_file}")
        
        # æ˜¾ç¤ºæ•°æ®æ ¼å¼è¯´æ˜
        show_data_format_info()
        
        # æ˜¾ç¤ºè®­ç»ƒé›†æ ·ä¾‹
        show_data_sample(train_path, num_samples=2)
        
        # æ˜¾ç¤ºéªŒè¯é›†æ ·ä¾‹
        show_data_sample(val_path, num_samples=1)
        
        print(f"\nğŸ¯ ä¸‹ä¸€æ­¥ï¼š")
        print(f"   1. ä½¿ç”¨ {train_path} å’Œ {val_path} è¿›è¡ŒRLè®­ç»ƒ")
        print(f"   2. é…ç½®verlè®­ç»ƒè„šæœ¬ï¼ŒæŒ‡å®šæ•°æ®è·¯å¾„")
        print(f"   3. è®¾ç½®å¥–åŠ±å‡½æ•°æ¥è¯„ä¼°SQLç”Ÿæˆè´¨é‡")
        print(f"   4. å¯åŠ¨PPOæˆ–å…¶ä»–RLç®—æ³•è¿›è¡Œæ¨¡å‹ä¼˜åŒ–")
        
        # æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
        df_train = pd.read_parquet(train_path)
        df_val = pd.read_parquet(val_path)
        
        print(f"   è®­ç»ƒé›†å¤§å°: {train_path.stat().st_size / (1024*1024):.1f} MB")
        print(f"   éªŒè¯é›†å¤§å°: {val_path.stat().st_size / (1024*1024):.1f} MB")
        print(f"   æ•°æ®æºåˆ†å¸ƒ: {df_train['data_source'].value_counts().to_dict()}")
        print(f"   èƒ½åŠ›ç±»åˆ«åˆ†å¸ƒ: {df_train['ability'].value_counts().to_dict()}")
        
    except Exception as e:
        print(f"âŒ RLæ•°æ®è½¬æ¢å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 