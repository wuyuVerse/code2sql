# Code2SQL项目批量重新分析功能开发

## 对话总结

**日期**: 2025年7月3日  
**主题**: 开发高并发批量重新分析脚本，验证无法生成SQL的记录  
**目标**: 创建一个独立的脚本，使用优化后的提示词和高并发设置，对数据集中被标记为`<NO SQL GENERATE>`的记录进行重新分析，以验证其准确性。

## 功能需求

为了评估和提升数据生成的质量，需要一个工具来完成以下任务：
1.  **加载特定数据集**: 读取指定的JSON文件（例如 `final_processed_dataset.json`）。
2.  **筛选目标记录**: 找出所有`sql_statement_list`字段为`<NO SQL GENERATE>`的条目。
3.  **使用优化提示词**: 应用一个新的、更详细的提示词来指导LLM进行分析。
4.  **高并发执行**: 使用200的并发量调用`v3` LLM服务器，以加速处理过程。
5.  **输出验证结果**: 将新的分析结果保存下来，方便与原始标记进行对比。

## 技术实现方案

为了满足上述需求，我们设计并实现了一个全新的解决方案，包含以下两个核心部分：

### 1. 提示词管理 (`config/prompts.py`)

为了使提示词易于管理和复用，我们创建了一个新的配置文件：
- **文件路径**: `config/prompts.py`
- **内容**: 将用户提供的优化版提示词保存为一个名为`REANALYSIS_PROMPT`的常量。

这种方式将提示词内容与业务逻辑代码分离，提高了代码的可维护性。

### 2. 批量分析脚本 (`rerun_analysis.py`)

我们创建了一个功能强大的独立脚本`rerun_analysis.py`，它负责整个批量处理流程。

**脚本核心功能**:
- **命令行接口**: 使用`argparse`库，支持通过命令行参数传入输入文件、输出文件、并发数和服务器名称，增加了脚本的灵活性。
- **数据加载与筛选**: 能够高效地加载JSON数据并筛选出目标记录。
- **动态提示词格式化**: `format_prompt`函数可以根据每条记录的具体内容（函数名、ORM代码、元数据等）动态构建完整的请求提示词。
- **高并发异步执行**:
    - 使用`asyncio`和`aiohttp`库来处理异步网络请求。
    - 通过`asyncio.Semaphore(200)`来精确控制并发量，防止对服务器造成过大压力。
    - 使用`tqdm`库显示实时进度条，提供了良好的用户交互体验。
- **健壮的错误处理**: 对文件未找到、JSON解析错误以及单次API调用失败等情况都做了try-except处理，确保脚本不会轻易中断。
- **详细的结果报告**: 脚本执行完毕后，会输出一个清晰的总结报告，包含总处理数、成功数、失败数、新生成SQL的记录数等关键指标。

## 使用方法

脚本可以通过以下命令来执行：
```bash
python rerun_analysis.py \
    --input-file /home/wuyu/code2sql/workflow_output/workflow_20250703_155430/final_processed_dataset.json \
    --output-file rerun_analysis_results.json \
    --concurrency 200 \
    --server v3
```

- `--input-file`: 指定包含`<NO SQL GENERATE>`记录的源文件。
- `--output-file`: 指定保存新分析结果的文件。
- `--concurrency`: 设置并发请求数（默认为200）。
- `--server`: 指定LLM服务器（默认为`v3`）。

## 最终交付成果

1.  **`config/prompts.py`**: 一个新的配置文件，用于存储和管理LLM提示词。
2.  **`rerun_analysis.py`**: 一个功能完整、健壮且用户友好的高并发批量分析脚本。

这个工具为数据质量的持续监控和迭代优化提供了一个强大的自动化解决方案，是数据驱动项目中的一个重要实践。 