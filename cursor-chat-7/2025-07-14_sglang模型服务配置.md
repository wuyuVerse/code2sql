# 2025-07-14 SGLang模型服务配置对话总结

## 对话主题
用户需要了解如何查看conda环境，并使用sglang启动模型服务以替代原有的LLaMA-Factory启动方式，开启推理加速以避免timeout问题。

## 主要任务

### 1. 查看conda环境
- 使用 `conda env list` 命令查看现有环境
- 发现存在 `sglang` 环境，版本为 0.4.9.post2

### 2. 探索sglang功能
- 查看sglang的安装位置和可用命令
- 了解sglang的启动参数和配置选项
- 发现sglang提供更高效的推理引擎和多GPU支持

### 3. 配置sglang启动命令
- 设计使用2张GPU进行tensor parallel的启动命令
- 配置性能优化参数：
  - `--tensor-parallel-size 2`: 启用tensor parallel
  - `--max-running-requests 100`: 增加并发处理能力
  - `--max-total-tokens 8192`: 设置更大的token池
  - `--enable-metrics`: 启用性能监控
  - `--log-requests`: 记录请求日志

### 4. 创建访问使用指南
- 创建测试脚本：`test_sglang_api.py` 和 `test_sglang_curl.sh`
- 编写完整的使用指南：`sglang_usage_guide.md`
- 提供多种API访问方式：HTTP API、Python API、curl测试

## 技术方案

### 启动命令对比
```bash
# 原有LLaMA-Factory命令
nohup env CUDA_VISIBLE_DEVICES=7 API_HOST=0.0.0.0 API_PORT=8001 API_MODEL_NAME=code2sql uv run python -m llamafactory.cli api --model_name_or_path /home/wuyu/code2sql/saves/qwen3-14b-ft-20250710_154849 --template qwen > code2sql_8001.log 2>&1 &

# 新的sglang命令
nohup env CUDA_VISIBLE_DEVICES=6,7 python -m sglang.launch_server --model-path /home/wuyu/code2sql/saves/qwen3-14b-ft-20250710_154849 --host 0.0.0.0 --port 8001 --tensor-parallel-size 2 --tp-size 2 --max-running-requests 100 --max-total-tokens 8192 --enable-metrics --log-requests --log-requests-level 1 > code2sql_sglang_8001.log 2>&1 &
```

### API访问方式
1. **HTTP API（OpenAI兼容）**：
   - 健康检查：`GET /health`
   - 模型信息：`GET /v1/models`
   - 聊天API：`POST /v1/chat/completions`
   - 流式API：支持stream参数

2. **Python API**：
   ```python
   from sglang import set_default_backend, user, assistant, gen
   set_default_backend("http://localhost:8001")
   s = user("你好，请用SQL查询所有年龄大于20岁的用户")
   s += assistant(gen(max_tokens=256, temperature=0.1))
   response = s.run()
   ```

## 优势分析

### 相比LLaMA-Factory的优势
1. **推理加速**：sglang提供更高效的推理引擎
2. **多卡并行**：通过tensor parallel提升吞吐量
3. **更好的并发**：支持更多并发请求
4. **性能监控**：内置metrics和日志功能
5. **内存效率**：更优的内存管理

### 性能优化配置
- 使用2张GPU进行tensor parallel
- 增加并发请求数和token池大小
- 启用性能监控和请求日志
- 支持流式响应

## 交付成果

### 创建的文件
1. `test_sglang_api.py` - Python API测试脚本
2. `test_sglang_curl.sh` - Bash API测试脚本
3. `sglang_usage_guide.md` - 完整使用指南

### 使用指南包含
- 启动服务配置
- API访问方式（HTTP、Python、curl）
- 性能优化建议
- 监控和日志配置
- 故障排除指南
- 与LLaMA-Factory的对比

## 建议的迁移步骤

1. **测试验证**：先在测试环境验证sglang功能
2. **性能对比**：对比两种方式的响应时间和吞吐量
3. **监控完善**：确保监控和日志功能正常
4. **逐步迁移**：逐步替换原有服务
5. **回滚方案**：保留原有LLaMA-Factory配置作为备选

## 技术要点

- sglang提供更高效的推理引擎，适合高并发场景
- 多GPU tensor parallel配置可显著提升性能
- 完整的监控和日志功能便于问题排查
- 兼容OpenAI API格式，便于集成现有系统 