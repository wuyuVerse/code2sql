# 对话总结：工作流新增LLM数据标记与进度条功能

## 核心需求
用户要求在`data_processing/workflow/workflow_manager.py`中增加一个新步骤：在SQL清洗之后，使用LLM并发检查每条数据的SQL生成完整性，并为不完善的数据打上`<LACK INFORMATION>`标签。后续，用户要求为这个并发处理过程增加进度条。

## 实施方案

### 1. LLM数据标记步骤
- **新增提示词配置**：
  - 创建 `config/data_clean/sql_completeness_check_prompt.py`，定义了详细的SQL完整性判断标准和格式化输出要求。
- **扩展工作流管理器**：
  - 在`WorkflowManager`类中添加了新的异步方法 `tag_lack_information_data`。
  - 该方法使用`aiohttp`和`asyncio`实现 **100个并发** 的LLM API调用（v3接口）。
  - 根据LLM返回结果（"是"或"否"），智能地为不完善的数据记录添加`completeness_check`元数据，并在`function_name`前加上`<LACK INFORMATION>`标签。
  - 具备完整的容错机制，处理失败的记录会被标记，但不会中断整个流程。
- **工作流集成**：
  - 在主工作流函数 `run_complete_workflow_from_raw_data` 的SQL清洗步骤后，插入了新的LLM标记步骤。
  - 调整了后续步骤的命名（step3, step4...）以保持逻辑清晰。
  - 更新了`print_workflow_summary`方法，使其能够识别并打印新步骤的统计结果（如标记数量、缺少信息率等）。

### 2. 进度条功能
- **背景**：用户发现LLM并发处理过程耗时较长，无法了解当前进度。
- **实现**：
  - 引入 `tqdm` 库，特别是 `tqdm.asyncio`。
  - 在`tag_lack_information_data`方法中，使用`tqdm`的回调函数机制 (`add_done_callback`)来包装异步任务。
  - **效果**：在保持数据处理顺序和并发效率的同时，实现了在终端实时更新的进度条，清晰地展示了已处理的记录数量和总进度。

### 3. 调试与优化过程
- **数据路径错误**：
  - **问题**：测试脚本 `test_workflow_with_tagging.py` 中硬编码的数据目录不正确。
  - **解决**：根据用户提供的正确路径 `datasets/claude_outputs` 进行了修正，并处理了`claude_outputs`与`claude_output`的拼写差异。
- **模块导入错误**：
  - **问题**：由于项目目录结构调整，`utils/llm_client.py` 中对`llm_config`的导入路径失效。
  - **解决**：将导入路径从 `config.llm_config` 修改为 `config.llm.llm_config`。
- **配置文件路径错误**：
  - **问题**：`llm_config.py` 内部加载 `servers.yaml` 的默认路径不正确。
  - **解决**：将默认路径从 `config/servers.yaml` 修正为 `config/llm/servers.yaml`。
- **输出目录调整**：
  - **要求**：用户希望将测试输出目录从 `workflow_output_with_tagging` 改为通用的 `workflow_output`。
  - **解决**：修改了测试脚本中的`output_dir`变量。

## 最终成果
- 成功为数据处理工作流增加了一个高效、自动化的LLM数据标记环节。
- 通过引入进度条，极大地改善了长耗时任务的用户体验。
- 修复了多处因代码重构引起的文件路径和模块导入问题，提升了代码的健壮性。
- 创建了 `test_workflow_with_tagging.py` 脚本，便于后续对该功能的回归测试。

---
**实施状态**: ✅ 已完成
**测试状态**: ✅ 已通过测试脚本验证
**用户体验**: ✅ 已增加进度条，提升可观测性 