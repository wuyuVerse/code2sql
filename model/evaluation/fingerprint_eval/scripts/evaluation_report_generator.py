#!/usr/bin/env python3
"""
è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨

åˆ†ææ¨¡å‹è¯„ä¼°ç»“æœå¹¶ç”Ÿæˆè¯¦ç»†çš„å¯è§†åŒ–æŠ¥å‘Š
"""

import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import argparse
from collections import defaultdict, Counter
import re

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EvaluationReportGenerator:
    """è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self, results_file: str, output_dir: str = "evaluation_reports"):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        
        Args:
            results_file: è¯„ä¼°ç»“æœæ–‡ä»¶è·¯å¾„
            output_dir: æŠ¥å‘Šè¾“å‡ºç›®å½•
        """
        self.results_file = Path(results_file)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½è¯„ä¼°ç»“æœ
        self.evaluation_data = self.load_evaluation_results()
        self.config = self.evaluation_data.get('config', {})
        self.statistics = self.evaluation_data.get('statistics', {})
        self.detailed_results = self.evaluation_data.get('detailed_results', [])
        
        logger.info(f"å·²åŠ è½½è¯„ä¼°ç»“æœ: {self.results_file}")
        logger.info(f"æŠ¥å‘Šè¾“å‡ºç›®å½•: {self.output_dir}")
    
    def load_evaluation_results(self) -> Dict:
        """åŠ è½½è¯„ä¼°ç»“æœ"""
        if not self.results_file.exists():
            raise FileNotFoundError(f"è¯„ä¼°ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {self.results_file}")
        
        with open(self.results_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def analyze_sql_patterns(self) -> Dict:
        """åˆ†æSQLæ¨¡å¼"""
        logger.info("å¼€å§‹åˆ†æSQLæ¨¡å¼...")
        
        sql_type_stats = defaultdict(int)
        sql_complexity_stats = defaultdict(int)
        sql_length_stats = []
        common_patterns = defaultdict(int)
        error_patterns = defaultdict(int)
        
        for result in self.detailed_results:
            parsed_sql = result.get('parsed_sql', [])
            sql_evaluation = result.get('sql_evaluation', {})
            
            # åˆ†ææ¯ä¸ªSQL
            for sql in parsed_sql:
                if not sql.strip():
                    continue
                
                # SQLç±»å‹åˆ†æ
                sql_type = self.determine_sql_type(sql)
                sql_type_stats[sql_type] += 1
                
                # SQLé•¿åº¦ç»Ÿè®¡
                sql_length_stats.append(len(sql))
                
                # å¤æ‚åº¦åˆ†æ
                complexity = self.analyze_sql_complexity(sql)
                sql_complexity_stats[complexity] += 1
                
                # å¸¸è§æ¨¡å¼æ£€æµ‹
                patterns = self.extract_sql_patterns(sql)
                for pattern in patterns:
                    common_patterns[pattern] += 1
            
            # é”™è¯¯æ¨¡å¼åˆ†æ
            if result.get('parse_error'):
                error_type = self.classify_error(result['parse_error'])
                error_patterns[error_type] += 1
        
        return {
            'sql_type_distribution': dict(sql_type_stats),
            'complexity_distribution': dict(sql_complexity_stats),
            'length_statistics': {
                'avg_length': sum(sql_length_stats) / len(sql_length_stats) if sql_length_stats else 0,
                'min_length': min(sql_length_stats) if sql_length_stats else 0,
                'max_length': max(sql_length_stats) if sql_length_stats else 0,
                'total_sqls': len(sql_length_stats)
            },
            'common_patterns': dict(sorted(common_patterns.items(), key=lambda x: x[1], reverse=True)[:20]),
            'error_patterns': dict(error_patterns)
        }
    
    def determine_sql_type(self, sql: str) -> str:
        """ç¡®å®šSQLç±»å‹"""
        sql_clean = re.sub(r'/\*.*?\*/', '', sql, flags=re.DOTALL)
        sql_clean = re.sub(r'--.*?$', '', sql_clean, flags=re.MULTILINE)
        sql_clean = sql_clean.strip().upper()
        
        if sql_clean.startswith('SELECT'):
            return 'SELECT'
        elif sql_clean.startswith('INSERT'):
            return 'INSERT'
        elif sql_clean.startswith('UPDATE'):
            return 'UPDATE'
        elif sql_clean.startswith('DELETE'):
            return 'DELETE'
        elif sql_clean.startswith(('CREATE', 'ALTER', 'DROP')):
            return 'DDL'
        else:
            return 'OTHER'
    
    def analyze_sql_complexity(self, sql: str) -> str:
        """åˆ†æSQLå¤æ‚åº¦"""
        sql_upper = sql.upper()
        
        # è®¡ç®—å¤æ‚åº¦ç‰¹å¾
        join_count = len(re.findall(r'\bJOIN\b', sql_upper))
        subquery_count = sql.count('(') + sql.count(')')
        where_clauses = len(re.findall(r'\bWHERE\b', sql_upper))
        having_clauses = len(re.findall(r'\bHAVING\b', sql_upper))
        
        # å¤æ‚åº¦è¯„åˆ†
        complexity_score = join_count * 2 + subquery_count + where_clauses + having_clauses
        
        if complexity_score <= 2:
            return 'SIMPLE'
        elif complexity_score <= 8:
            return 'MEDIUM'
        else:
            return 'COMPLEX'
    
    def extract_sql_patterns(self, sql: str) -> List[str]:
        """æå–SQLæ¨¡å¼"""
        patterns = []
        sql_upper = sql.upper()
        
        # å¸¸è§æ¨¡å¼æ£€æµ‹
        if 'JOIN' in sql_upper:
            patterns.append('HAS_JOIN')
        if 'WHERE' in sql_upper:
            patterns.append('HAS_WHERE')
        if 'GROUP BY' in sql_upper:
            patterns.append('HAS_GROUP_BY')
        if 'ORDER BY' in sql_upper:
            patterns.append('HAS_ORDER_BY')
        if 'LIMIT' in sql_upper:
            patterns.append('HAS_LIMIT')
        if 'UNION' in sql_upper:
            patterns.append('HAS_UNION')
        if re.search(r'\bCOUNT\s*\(', sql_upper):
            patterns.append('HAS_COUNT')
        if re.search(r'\b(SUM|AVG|MIN|MAX)\s*\(', sql_upper):
            patterns.append('HAS_AGGREGATION')
        if '?' in sql or ':' in sql:
            patterns.append('HAS_PARAMETERS')
        
        return patterns
    
    def classify_error(self, error_msg: str) -> str:
        """åˆ†ç±»é”™è¯¯ç±»å‹"""
        error_lower = error_msg.lower()
        
        if 'json' in error_lower:
            return 'JSON_PARSE_ERROR'
        elif 'sql' in error_lower:
            return 'SQL_ERROR'
        elif 'timeout' in error_lower:
            return 'TIMEOUT_ERROR'
        elif 'memory' in error_lower:
            return 'MEMORY_ERROR'
        else:
            return 'OTHER_ERROR'
    
    def analyze_fingerprint_coverage(self) -> Dict:
        """åˆ†ææŒ‡çº¹è¦†ç›–æƒ…å†µ"""
        logger.info("å¼€å§‹åˆ†ææŒ‡çº¹è¦†ç›–æƒ…å†µ...")
        
        total_fingerprints = 0
        matched_fingerprints = 0
        fingerprint_distribution = defaultdict(int)
        unmatched_patterns = defaultdict(int)
        
        for result in self.detailed_results:
            sql_evaluation = result.get('sql_evaluation', {})
            fingerprint_results = sql_evaluation.get('fingerprint_results', [])
            
            for fp_result in fingerprint_results:
                total_fingerprints += 1
                match_result = fp_result.get('match_result', {})
                
                if match_result.get('matched', False):
                    matched_fingerprints += 1
                    fingerprint = match_result.get('fingerprint', 'unknown')
                    fingerprint_distribution[fingerprint] += 1
                else:
                    # åˆ†ææœªåŒ¹é…çš„æ¨¡å¼
                    sql = fp_result.get('sql', '')
                    pattern = self.determine_sql_type(sql)
                    unmatched_patterns[pattern] += 1
        
        coverage_rate = matched_fingerprints / total_fingerprints if total_fingerprints > 0 else 0
        
        return {
            'total_fingerprints': total_fingerprints,
            'matched_fingerprints': matched_fingerprints,
            'coverage_rate': coverage_rate,
            'fingerprint_distribution': dict(sorted(fingerprint_distribution.items(), key=lambda x: x[1], reverse=True)[:20]),
            'unmatched_patterns': dict(unmatched_patterns)
        }
    
    def analyze_quality_metrics(self) -> Dict:
        """åˆ†æè´¨é‡æŒ‡æ ‡"""
        logger.info("å¼€å§‹åˆ†æè´¨é‡æŒ‡æ ‡...")
        
        # æŒ‰æ ·æœ¬åˆ†æ
        sample_quality = []
        for result in self.detailed_results:
            inference_success = result.get('inference_success', False)
            parsed_sql = result.get('parsed_sql', [])
            sql_evaluation = result.get('sql_evaluation', {})
            
            quality_score = 0
            if inference_success:
                quality_score += 1
            if parsed_sql:
                quality_score += 1
            if sql_evaluation.get('valid_sql', 0) > 0:
                quality_score += 1
            if sql_evaluation.get('matched_sql', 0) > 0:
                quality_score += 2
            
            sample_quality.append(quality_score)
        
        # è´¨é‡åˆ†å¸ƒ
        quality_distribution = Counter(sample_quality)
        
        # è´¨é‡é˜ˆå€¼åˆ†æ
        high_quality_samples = sum(1 for score in sample_quality if score >= 4)
        medium_quality_samples = sum(1 for score in sample_quality if 2 <= score < 4)
        low_quality_samples = sum(1 for score in sample_quality if score < 2)
        
        return {
            'quality_distribution': dict(quality_distribution),
            'quality_thresholds': {
                'high_quality': high_quality_samples,
                'medium_quality': medium_quality_samples,
                'low_quality': low_quality_samples
            },
            'average_quality_score': sum(sample_quality) / len(sample_quality) if sample_quality else 0
        }
    
    def find_representative_examples(self, num_examples: int = 5) -> Dict:
        """å¯»æ‰¾ä»£è¡¨æ€§ç¤ºä¾‹"""
        logger.info("å¼€å§‹å¯»æ‰¾ä»£è¡¨æ€§ç¤ºä¾‹...")
        
        examples = {
            'excellent': [],
            'good': [],
            'poor': [],
            'failed': []
        }
        
        for result in self.detailed_results:
            inference_success = result.get('inference_success', False)
            parsed_sql = result.get('parsed_sql', [])
            sql_evaluation = result.get('sql_evaluation', {})
            
            sample_summary = {
                'sample_id': result.get('sample_id', ''),
                'prompt': result.get('prompt', '')[:200] + '...',  # æˆªå–å‰200å­—ç¬¦
                'response': result.get('response', ''),
                'parsed_sql': parsed_sql,
                'valid_sql_count': sql_evaluation.get('valid_sql', 0),
                'matched_sql_count': sql_evaluation.get('matched_sql', 0)
            }
            
            # åˆ†ç±»ç¤ºä¾‹
            if not inference_success:
                if len(examples['failed']) < num_examples:
                    examples['failed'].append(sample_summary)
            elif sql_evaluation.get('matched_sql', 0) > 0:
                if len(examples['excellent']) < num_examples:
                    examples['excellent'].append(sample_summary)
            elif sql_evaluation.get('valid_sql', 0) > 0:
                if len(examples['good']) < num_examples:
                    examples['good'].append(sample_summary)
            else:
                if len(examples['poor']) < num_examples:
                    examples['poor'].append(sample_summary)
        
        return examples
    
    def generate_html_report(self) -> str:
        """ç”ŸæˆHTMLæ ¼å¼çš„æŠ¥å‘Š"""
        logger.info("å¼€å§‹ç”ŸæˆHTMLæŠ¥å‘Š...")
        
        # åˆ†ææ•°æ®
        sql_analysis = self.analyze_sql_patterns()
        fingerprint_analysis = self.analyze_fingerprint_coverage()
        quality_analysis = self.analyze_quality_metrics()
        examples = self.find_representative_examples()
        
        # ç”ŸæˆHTMLå†…å®¹
        html_content = f"""
        <!DOCTYPE html>
        <html lang="zh-CN">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>æ¨¡å‹è¯„ä¼°æŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; color: #333; border-bottom: 2px solid #007bff; padding-bottom: 20px; margin-bottom: 30px; }}
                .section {{ margin-bottom: 30px; }}
                .section-title {{ color: #007bff; font-size: 1.5em; margin-bottom: 15px; border-left: 4px solid #007bff; padding-left: 10px; }}
                .metric-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-bottom: 20px; }}
                .metric-card {{ background: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 4px solid #28a745; }}
                .metric-value {{ font-size: 2em; font-weight: bold; color: #28a745; }}
                .metric-label {{ color: #666; font-size: 0.9em; }}
                .chart-container {{ background: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}
                table {{ width: 100%; border-collapse: collapse; margin-bottom: 20px; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #007bff; color: white; }}
                .example-box {{ background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 8px; border-left: 4px solid #17a2b8; }}
                .code {{ background: #f4f4f4; padding: 10px; border-radius: 4px; font-family: monospace; margin: 10px 0; overflow-x: auto; }}
                .excellent {{ border-left-color: #28a745; }}
                .good {{ border-left-color: #ffc107; }}
                .poor {{ border-left-color: #fd7e14; }}
                .failed {{ border-left-color: #dc3545; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ¤– æ¨¡å‹è¯„ä¼°æŠ¥å‘Š</h1>
                    <p>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                    <p>æ¨¡å‹è·¯å¾„: {self.config.get('model_config', {}).get('model_path', 'Unknown')}</p>
                </div>
                
                <div class="section">
                    <h2 class="section-title">ğŸ“Š æ€»ä½“ç»Ÿè®¡</h2>
                    <div class="metric-grid">
                        <div class="metric-card">
                            <div class="metric-value">{self.statistics.get('total_samples', 0)}</div>
                            <div class="metric-label">æ€»æ ·æœ¬æ•°</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{self.statistics.get('inference_success_rate', 0):.1%}</div>
                            <div class="metric-label">æ¨ç†æˆåŠŸç‡</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{self.statistics.get('valid_sql_rate', 0):.1%}</div>
                            <div class="metric-label">æœ‰æ•ˆSQLç”Ÿæˆç‡</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{self.statistics.get('fingerprint_match_rate', 0):.1%}</div>
                            <div class="metric-label">æŒ‡çº¹åŒ¹é…ç‡</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{self.statistics.get('total_sql_generated', 0)}</div>
                            <div class="metric-label">æ€»ç”ŸæˆSQLæ•°</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{self.statistics.get('sql_validity_rate', 0):.1%}</div>
                            <div class="metric-label">SQLæœ‰æ•ˆæ€§æ¯”ç‡</div>
                        </div>
                    </div>
                </div>
                
                <div class="section">
                    <h2 class="section-title">ğŸ¯ SQLæ¨¡å¼åˆ†æ</h2>
                    <div class="chart-container">
                        <h3>SQLç±»å‹åˆ†å¸ƒ</h3>
                        <table>
                            <tr><th>SQLç±»å‹</th><th>æ•°é‡</th><th>å æ¯”</th></tr>
                            {self._generate_table_rows(sql_analysis['sql_type_distribution'])}
                        </table>
                    </div>
                    
                    <div class="chart-container">
                        <h3>SQLå¤æ‚åº¦åˆ†å¸ƒ</h3>
                        <table>
                            <tr><th>å¤æ‚åº¦</th><th>æ•°é‡</th><th>å æ¯”</th></tr>
                            {self._generate_table_rows(sql_analysis['complexity_distribution'])}
                        </table>
                    </div>
                    
                    <div class="chart-container">
                        <h3>å¸¸è§SQLæ¨¡å¼ (Top 10)</h3>
                        <table>
                            <tr><th>æ¨¡å¼</th><th>å‡ºç°æ¬¡æ•°</th></tr>
                            {self._generate_pattern_table(sql_analysis['common_patterns'])}
                        </table>
                    </div>
                </div>
                
                <div class="section">
                    <h2 class="section-title">ğŸ” æŒ‡çº¹è¦†ç›–åˆ†æ</h2>
                    <div class="metric-grid">
                        <div class="metric-card">
                            <div class="metric-value">{fingerprint_analysis['total_fingerprints']}</div>
                            <div class="metric-label">æ€»æŒ‡çº¹æ•°</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{fingerprint_analysis['matched_fingerprints']}</div>
                            <div class="metric-label">åŒ¹é…æŒ‡çº¹æ•°</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{fingerprint_analysis['coverage_rate']:.1%}</div>
                            <div class="metric-label">è¦†ç›–ç‡</div>
                        </div>
                    </div>
                </div>
                
                <div class="section">
                    <h2 class="section-title">â­ è´¨é‡åˆ†æ</h2>
                    <div class="metric-grid">
                        <div class="metric-card excellent">
                            <div class="metric-value">{quality_analysis['quality_thresholds']['high_quality']}</div>
                            <div class="metric-label">é«˜è´¨é‡æ ·æœ¬</div>
                        </div>
                        <div class="metric-card good">
                            <div class="metric-value">{quality_analysis['quality_thresholds']['medium_quality']}</div>
                            <div class="metric-label">ä¸­ç­‰è´¨é‡æ ·æœ¬</div>
                        </div>
                        <div class="metric-card poor">
                            <div class="metric-value">{quality_analysis['quality_thresholds']['low_quality']}</div>
                            <div class="metric-label">ä½è´¨é‡æ ·æœ¬</div>
                        </div>
                        <div class="metric-card">
                            <div class="metric-value">{quality_analysis['average_quality_score']:.1f}</div>
                            <div class="metric-label">å¹³å‡è´¨é‡åˆ†æ•°</div>
                        </div>
                    </div>
                </div>
                
                <div class="section">
                    <h2 class="section-title">ğŸ“ ä»£è¡¨æ€§ç¤ºä¾‹</h2>
                    {self._generate_examples_html(examples)}
                </div>
                
                <div class="section">
                    <h2 class="section-title">ğŸ”§ é…ç½®ä¿¡æ¯</h2>
                    <div class="code">
                        {json.dumps(self.config, indent=2, ensure_ascii=False)[:1000]}...
                    </div>
                </div>
            </div>
        </body>
        </html>
        """
        
        # ä¿å­˜HTMLæŠ¥å‘Š
        html_file = self.output_dir / "evaluation_report.html"
        
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        logger.info(f"HTMLæŠ¥å‘Šå·²ä¿å­˜: {html_file}")
        return str(html_file)
    
    def _generate_table_rows(self, data: Dict) -> str:
        """ç”Ÿæˆè¡¨æ ¼è¡Œ"""
        total = sum(data.values()) if data else 1
        rows = []
        for key, value in data.items():
            percentage = (value / total) * 100
            rows.append(f"<tr><td>{key}</td><td>{value}</td><td>{percentage:.1f}%</td></tr>")
        return "".join(rows)
    
    def _generate_pattern_table(self, data: Dict) -> str:
        """ç”Ÿæˆæ¨¡å¼è¡¨æ ¼"""
        rows = []
        for pattern, count in list(data.items())[:10]:
            rows.append(f"<tr><td>{pattern}</td><td>{count}</td></tr>")
        return "".join(rows)
    
    def _generate_examples_html(self, examples: Dict) -> str:
        """ç”Ÿæˆç¤ºä¾‹HTML"""
        html_parts = []
        
        for category, example_list in examples.items():
            if not example_list:
                continue
                
            category_names = {
                'excellent': 'ğŸŒŸ ä¼˜ç§€ç¤ºä¾‹',
                'good': 'ğŸ‘ è‰¯å¥½ç¤ºä¾‹', 
                'poor': 'âš ï¸ è¾ƒå·®ç¤ºä¾‹',
                'failed': 'âŒ å¤±è´¥ç¤ºä¾‹'
            }
            
            html_parts.append(f"<h3>{category_names.get(category, category)}</h3>")
            
            for i, example in enumerate(example_list[:3]):  # é™åˆ¶æ¯ç±»æœ€å¤š3ä¸ªç¤ºä¾‹
                html_parts.append(f"""
                <div class="example-box {category}">
                    <h4>ç¤ºä¾‹ {i+1}: {example['sample_id']}</h4>
                    <p><strong>æç¤ºè¯ç‰‡æ®µ:</strong> {example['prompt']}</p>
                    <p><strong>æ¨¡å‹å“åº”:</strong></p>
                    <div class="code">{example['response'][:300]}{'...' if len(example['response']) > 300 else ''}</div>
                    <p><strong>è§£æSQLæ•°é‡:</strong> {len(example['parsed_sql'])}</p>
                    <p><strong>æœ‰æ•ˆSQL:</strong> {example['valid_sql_count']} | <strong>åŒ¹é…SQL:</strong> {example['matched_sql_count']}</p>
                </div>
                """)
        
        return "".join(html_parts)
    
    def generate_json_report(self) -> str:
        """ç”ŸæˆJSONæ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š"""
        logger.info("å¼€å§‹ç”ŸæˆJSONæŠ¥å‘Š...")
        
        report_data = {
            'metadata': {
                'generation_time': datetime.now().isoformat(),
                'model_path': self.config.get('model_config', {}).get('model_path'),
                'eval_data_path': self.config.get('data_config', {}).get('eval_data_path'),
                'total_samples': self.statistics.get('total_samples', 0)
            },
            'overall_statistics': self.statistics,
            'sql_analysis': self.analyze_sql_patterns(),
            'fingerprint_analysis': self.analyze_fingerprint_coverage(),
            'quality_analysis': self.analyze_quality_metrics(),
            'representative_examples': self.find_representative_examples(3),
            'configuration': self.config
        }
        
        json_file = self.output_dir / "detailed_analysis.json"
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"JSONæŠ¥å‘Šå·²ä¿å­˜: {json_file}")
        return str(json_file)
    
    def generate_all_reports(self) -> Dict[str, str]:
        """ç”Ÿæˆæ‰€æœ‰æ ¼å¼çš„æŠ¥å‘Š"""
        logger.info("å¼€å§‹ç”Ÿæˆå®Œæ•´æŠ¥å‘Š...")
        
        reports = {
            'html_report': self.generate_html_report(),
            'json_report': self.generate_json_report()
        }
        
        logger.info("æ‰€æœ‰æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        return reports


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨")
    parser.add_argument("--results_file", type=str, required=True, help="è¯„ä¼°ç»“æœæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_dir", type=str, required=True, help="æŠ¥å‘Šè¾“å‡ºç›®å½•")
    parser.add_argument("--format", type=str, choices=['html', 'json', 'all'], default='all', help="æŠ¥å‘Šæ ¼å¼")
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºæŠ¥å‘Šç”Ÿæˆå™¨
        generator = EvaluationReportGenerator(args.results_file, args.output_dir)
        
        # ç”ŸæˆæŠ¥å‘Š
        if args.format == 'html':
            html_report = generator.generate_html_report()
            print(f"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_report}")
        elif args.format == 'json':
            json_report = generator.generate_json_report()
            print(f"âœ… JSONæŠ¥å‘Šå·²ç”Ÿæˆ: {json_report}")
        else:
            reports = generator.generate_all_reports()
            print("âœ… æ‰€æœ‰æŠ¥å‘Šå·²ç”Ÿæˆ:")
            for report_type, path in reports.items():
                print(f"  - {report_type}: {path}")
        
    except Exception as e:
        logger.error(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main() 