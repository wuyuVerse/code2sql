#!/usr/bin/env python3
"""
æµ‹è¯•SQLæ¸…æ´—åŠŸèƒ½ï¼ˆåŒ…å«ORM SQLæŒ‡çº¹åˆ†æï¼‰
"""

import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from data_processing.workflow.workflow_manager import WorkflowManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§¹ å¼€å§‹æµ‹è¯•SQLæ¸…æ´—åŠŸèƒ½ï¼ˆåŒ…å«ORM SQLæŒ‡çº¹åˆ†æï¼‰")
    
    # é…ç½®å‚æ•°
    data_dir = "datasets/claude_output"  # åŸå§‹æ•°æ®ç›®å½•
    output_dir = "workflow_output"
    
    try:
        # åˆ›å»ºå·¥ä½œæµç®¡ç†å™¨
        workflow = WorkflowManager(base_output_dir=output_dir)
        
        print(f"ğŸ“ å·¥ä½œæµè¾“å‡ºç›®å½•: {workflow.workflow_dir}")
        
        # æ­¥éª¤1: åŠ è½½åŸå§‹æ•°æ®é›†
        print("\nğŸ“¥ æ­¥éª¤1: åŠ è½½åŸå§‹æ•°æ®é›†...")
        load_result = workflow.load_raw_dataset(data_dir)
        print(f"   âœ… æˆåŠŸåŠ è½½ {load_result['total_records_loaded']:,} æ¡è®°å½•")
        
        # è·å–åŸå§‹æ•°æ®ç»Ÿè®¡
        original_data = workflow.current_data
        if original_data is None:
            print("âŒ æ— æ³•è·å–åŸå§‹æ•°æ®")
            return 1
        total_records = len(original_data)
        
        # ç»Ÿè®¡åŸå§‹SQLæ•°æ®
        sql_stats = {
            'records_with_sql': 0,
            'total_sql_items': 0,
            'empty_sql_lists': 0,
            'records_with_orm_code': 0,
            'unique_orm_codes': set(),
            'unique_callers': set()
        }
        
        for record in original_data:
            sql_list = record.get('sql_statement_list', [])
            orm_code = record.get('orm_code', '')
            caller = record.get('caller', '')
            
            if sql_list:
                if isinstance(sql_list, list) and len(sql_list) > 0:
                    sql_stats['records_with_sql'] += 1
                    sql_stats['total_sql_items'] += len(sql_list)
                else:
                    sql_stats['empty_sql_lists'] += 1
            else:
                sql_stats['empty_sql_lists'] += 1
            
            if orm_code and orm_code.strip():
                sql_stats['records_with_orm_code'] += 1
                sql_stats['unique_orm_codes'].add(orm_code.strip())
            
            if caller and caller.strip():
                sql_stats['unique_callers'].add(caller.strip())
        
        print(f"\nğŸ“Š åŸå§‹æ•°æ®ç»Ÿè®¡:")
        print(f"   ğŸ“‹ æ€»è®°å½•æ•°: {total_records:,}")
        print(f"   ğŸ“ æœ‰SQLçš„è®°å½•: {sql_stats['records_with_sql']:,}")
        print(f"   ğŸ“„ æ€»SQLé¡¹æ•°: {sql_stats['total_sql_items']:,}")
        print(f"   ğŸ“­ ç©ºSQLåˆ—è¡¨: {sql_stats['empty_sql_lists']:,}")
        print(f"   ğŸ”§ æœ‰ORMä»£ç çš„è®°å½•: {sql_stats['records_with_orm_code']:,}")
        print(f"   ğŸ·ï¸ å”¯ä¸€ORMä»£ç æ•°: {len(sql_stats['unique_orm_codes']):,}")
        print(f"   ğŸ‘¤ å”¯ä¸€calleræ•°: {len(sql_stats['unique_callers']):,}")
        
        # æ­¥éª¤2: æ‰§è¡ŒSQLæ¸…æ´—ï¼ˆåŒ…å«ORMæŒ‡çº¹åˆ†æï¼‰
        print("\nğŸ§¹ æ­¥éª¤2: æ‰§è¡ŒSQLæ¸…æ´—ï¼ˆåŒ…å«ORMæŒ‡çº¹åˆ†æï¼‰...")
        cleaning_result = workflow.run_sql_cleaning("sql_cleaning_with_orm_analysis")
        
        print(f"   âœ… SQLæ¸…æ´—å®Œæˆ!")
        print(f"   ğŸ“Š æ¸…æ´—ç»Ÿè®¡:")
        print(f"      ğŸ“¥ è¾“å…¥è®°å½•: {cleaning_result['input_records_count']:,}")
        print(f"      ğŸ“¤ è¾“å‡ºè®°å½•: {cleaning_result['output_records_count']:,}")
        print(f"      ğŸ”„ ä¿®æ”¹è®°å½•: {cleaning_result['records_modified']:,}")
        print(f"      âŒ ç§»é™¤æ— æ•ˆSQL: {cleaning_result['invalid_sql_removed']:,}")
        print(f"      âœ… ä¿ç•™æœ‰æ•ˆSQL: {cleaning_result['valid_sql_retained']:,}")
        print(f"      ğŸ”§ ä¿ç•™å‚æ•°ä¾èµ–SQL: {cleaning_result['param_dependent_sql_retained']:,}")
        print(f"      ğŸ“­ å‘ç°ç©ºSQLåˆ—è¡¨: {cleaning_result.get('empty_sql_lists_found', 0):,}")
        print(f"      ğŸ—‚ï¸ æ¸…æ´—åå˜ç©ºåˆ—è¡¨: {cleaning_result.get('lists_emptied_after_cleaning', 0):,}")
        
        # æ˜¾ç¤ºORMåˆ†æç»“æœ
        if 'orm_analysis_summary' in cleaning_result and cleaning_result['orm_analysis_summary']:
            orm_summary = cleaning_result['orm_analysis_summary']
            print(f"\nğŸ” ORM SQLæŒ‡çº¹åˆ†æç»“æœ:")
            print(f"   ğŸ“Š åˆ†æçš„ORMä»£ç æ•°: {orm_summary['total_orm_codes']:,}")
            print(f"   ğŸ‘¥ æ€»calleræ•°: {orm_summary['total_callers']:,}")
            print(f"   ğŸ“ æ€»SQLè®°å½•æ•°: {orm_summary['total_sql_records']:,}")
            print(f"   ğŸ”„ æœ‰å¤šä¸ªcallerçš„ORM: {orm_summary['orm_with_multiple_callers']:,}")
            print(f"   ğŸ” æœ‰å†—ä½™SQLçš„ORM: {orm_summary['orm_with_redundant_sql']:,}")
            print(f"   âš ï¸ æœ‰æ½œåœ¨ç¼ºæ¼çš„ORM: {orm_summary['orm_with_potential_missing_extra']:,}")
            print(f"   ğŸ“ˆ å¹³å‡æ¯ORMçš„calleræ•°: {orm_summary['average_callers_per_orm']:.2f}")
            print(f"   ğŸ“ˆ å¹³å‡æ¯ORMçš„SQLæ•°: {orm_summary['average_sql_per_orm']:.2f}")
        
        # æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶è·¯å¾„
        if 'orm_analysis_reports' in cleaning_result and cleaning_result['orm_analysis_reports']:
            reports = cleaning_result['orm_analysis_reports']
            print(f"\nğŸ“„ ç”Ÿæˆçš„åˆ†ææŠ¥å‘Šæ–‡ä»¶:")
            print(f"   ğŸ“Š ORMç»Ÿè®¡æŠ¥å‘Š: {reports['orm_stats_file']}")
            print(f"   ğŸ” å†—ä½™SQLæŠ¥å‘Š: {reports['redundant_sql_file']}")
            print(f"   âš ï¸ ç¼ºæ¼SQLæŠ¥å‘Š: {reports['missing_extra_file']}")
            
            if 'summary' in reports:
                summary = reports['summary']
                print(f"\nğŸ“‹ æŠ¥å‘Šæ‘˜è¦:")
                print(f"   ğŸ“Š æ€»ORMä»£ç æ•°: {summary['total_orm_codes']:,}")
                print(f"   ğŸ” æœ‰å†—ä½™SQLçš„ORM: {summary['orm_with_redundant_sql']:,}")
                print(f"   âš ï¸ æœ‰ç¼ºæ¼/é¢å¤–SQLçš„ORM: {summary['orm_with_missing_extra']:,}")
        
        # æ˜¾ç¤ºè¾“å‡ºç›®å½•ä¿¡æ¯
        print(f"\nğŸ“ æ¸…æ´—ç»“æœå·²ä¿å­˜åˆ°: {cleaning_result['output_directory']}")
        
        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†æ ‡è®°å†—ä½™SQLçš„æ–‡ä»¶
        from pathlib import Path
        output_path = Path(cleaning_result['output_directory'])
        marked_file = output_path / "cleaned_records_with_redundant_marks.json"
        if marked_file.exists():
            print(f"   ğŸ·ï¸ å†—ä½™SQLæ ‡è®°æ–‡ä»¶: {marked_file}")
        
        # ä¿å­˜å·¥ä½œæµæ‘˜è¦
        summary_path = workflow.save_workflow_summary()
        print(f"   ğŸ“‹ å·¥ä½œæµæ‘˜è¦: {summary_path}")
        
        print(f"\nğŸ‰ SQLæ¸…æ´—æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ SQLæ¸…æ´—æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 