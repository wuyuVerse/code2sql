#!/usr/bin/env python3
# ä»workflow_output/workflow_20250709_205236 ç»§ç»­æ‰§è¡Œremove_no_sql_recordsæ­¥éª¤
#nohup uv run python test_workflow_keyword_first.py --resume workflow_output/workflow_20250709_205236 --from-step remove_no_sql_records >> output.txt 2>&1 &
# > output.txt 2>&1 &
"""
æµ‹è¯•ä»¥å…³é”®è¯æå–ä¼˜å…ˆçš„æ–°å·¥ä½œæµ
"""

import logging
import sys
import argparse
from pathlib import Path
import asyncio
from datetime import datetime
import random

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ Python è·¯å¾„ï¼Œæ–¹ä¾¿å¯¼å…¥
sys.path.append(str(Path(__file__).parent))

from data_processing.workflow.workflow_manager import WorkflowManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='è¿è¡Œå…³é”®è¯ä¼˜å…ˆçš„æ•°æ®å¤„ç†å·¥ä½œæµ')
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--data-dir', default='datasets/claude_output',
                        help='åŸå§‹æ•°æ®ç›®å½• (é»˜è®¤: datasets/claude_output)')
    parser.add_argument('--output-dir', default='workflow_output',
                        help='è¾“å‡ºåŸºç›®å½• (é»˜è®¤: workflow_output)')
    parser.add_argument('--keywords', nargs='*', default=None,
                        help='å…³é”®è¯åˆ—è¡¨ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤GORMå…³é”®è¯')
    
    # Resumeç›¸å…³å‚æ•°
    parser.add_argument('--resume', type=str, metavar='WORKFLOW_DIR',
                        help='ä»æŒ‡å®šçš„å·¥ä½œæµç›®å½•ç»§ç»­æ‰§è¡Œ')
    parser.add_argument('--from-step', type=str, metavar='STEP_NAME',
                        choices=['remove_no_sql_records', 'redundant_sql_validation', 
                                'sql_cleaning', 'keyword_extraction', 'export_final_data'],
                        help='ä»æŒ‡å®šæ­¥éª¤å¼€å§‹æ‰§è¡Œ')
    
    # æ§åˆ¶æ ‡å¿—
    parser.add_argument('--test', action='store_true',
                        help='å¼€å¯æµ‹è¯•æ¨¡å¼ï¼Œåªå¤„ç†10æ¡æ•°æ®')
    parser.add_argument('--reanalyze-no-sql', action='store_true', default=True,
                        help='åœ¨remove_no_sql_recordsæ­¥éª¤ä¸­æ˜¯å¦é‡æ–°åˆ†æNO SQLè®°å½• (é»˜è®¤: True)')
    parser.add_argument('--apply-fix', action='store_true', default=True,
                        help='åœ¨redundant_sql_validationæ­¥éª¤ä¸­æ˜¯å¦åº”ç”¨ä¿®å¤ (é»˜è®¤: True)')
    
    return parser.parse_args()


def run_new_workflow(args):
    """è¿è¡Œå…¨æ–°çš„å·¥ä½œæµ"""
    print("ğŸš€ å¼€å§‹è¿è¡Œå…¨æ–°çš„å…³é”®è¯ä¼˜å…ˆæ•°æ®å¤„ç†å·¥ä½œæµ")
    
    workflow = WorkflowManager(args.output_dir)
    
    try:
        # æ­¥éª¤ 1: åŠ è½½åŸå§‹æ•°æ®é›†
        load_result = workflow.load_raw_dataset(args.data_dir)
        
        # å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼ŒéšæœºæŠ½æ ·æ•°æ®
        if args.test:
            print("ğŸ§ª æµ‹è¯•æ¨¡å¼å¼€å¯ï¼ŒéšæœºæŠ½å–20æ¡æ•°æ®è¿›è¡Œå¤„ç†ã€‚")
            logging.info("ğŸ§ª æµ‹è¯•æ¨¡å¼å¼€å¯ï¼ŒéšæœºæŠ½å–20æ¡æ•°æ®è¿›è¡Œå¤„ç†ã€‚")
            if workflow.current_data and len(workflow.current_data) > 20:
                workflow.current_data = random.sample(workflow.current_data, 20)
                logging.info(f"æ•°æ®å·²é‡‡æ ·ï¼Œå‰©ä½™ {len(workflow.current_data)} æ¡è®°å½•ã€‚")

        # æ­¥éª¤ 2: æå–å…³é”®è¯æ•°æ®ï¼ˆé»˜è®¤ GORM å…³é”®è¯ï¼‰
        extraction_result = asyncio.run(workflow.extract_keyword_data(args.keywords, "keyword_extraction_step1", use_llm=True))

        # æ­¥éª¤ 2.5: ä½¿ç”¨LLMå¤„ç†å…³é”®è¯æ•°æ®
        process_keyword_result = asyncio.run(workflow.process_keyword_data_with_llm(step_name="process_keyword_data_step2"))

        # æ­¥éª¤ 3: ä»åŸå§‹æ•°æ®ä¸­åˆ†ç¦»å‡ºéå…³é”®è¯æ•°æ®ç”¨äºæ¸…æ´—
        original_data_list = workflow.current_data if workflow.current_data is not None else []
        processed_keyword_names = {rec["function_name"] for rec in (workflow.extracted_data or [])}
        non_keyword_data = [rec for rec in original_data_list if rec.get("function_name") not in processed_keyword_names]
        
        # è®°å½•åˆ†ç¦»æ­¥éª¤ä¿¡æ¯
        separation_step = {
            "step_name": "data_separation_after_keyword_processing",
            "step_type": "data_separation",
            "timestamp": datetime.now().isoformat(),
            "total_original_records": len(original_data_list),
            "processed_keyword_records": len(processed_keyword_names),
            "non_keyword_records_to_clean": len(non_keyword_data),
        }
        workflow.workflow_steps.append(separation_step)
        
        # æ­¥éª¤ 4: å¯¹éå…³é”®è¯æ•°æ®è¿›è¡Œæ¸…æ´—
        workflow.current_data = non_keyword_data  # æš‚æ—¶å°†å·¥ä½œæµæ ¸å¿ƒæ•°æ®è®¾ä¸ºéå…³é”®è¯æ•°æ®
        cleaning_result = workflow.run_sql_cleaning("sql_cleaning_after_extraction")
        no_sql_removal_result = asyncio.run(workflow.remove_no_sql_records("remove_no_sql_records_step", reanalyze_no_sql=True))
        fix_result = asyncio.run(workflow.run_redundant_sql_validation(
            apply_fix=True,
            step_name="redundant_sql_validation_with_fix",
        ))
        cleaned_non_keyword_data = workflow.current_data # ä¿å­˜æ¸…æ´—åçš„éå…³é”®è¯æ•°æ®

        # æ­¥éª¤ 5: åˆå¹¶å¤„ç†è¿‡çš„æ•°æ®
        processed_keyword_data = workflow.extracted_data or []
        final_data = cleaned_non_keyword_data + processed_keyword_data
        workflow.current_data = final_data
        
        # è®°å½•åˆå¹¶æ­¥éª¤
        total_records = len(final_data)
        updated_records = len(processed_keyword_data) + len(cleaned_non_keyword_data)
        merge_step = {
            "step_name": "final_data_merge",
            "step_type": "data_merging",
            "timestamp": datetime.now().isoformat(),
            "total_records": total_records,
            "updated_records": updated_records,
            "update_rate": 100.0 if total_records > 0 else 0.0,
        }
        workflow.workflow_steps.append(merge_step)
        
        # æ­¥éª¤ 6: å¯¼å‡ºæœ€ç»ˆæ•°æ®å’Œæ‘˜è¦
        final_data_path = workflow.export_final_data("final_processed_dataset.json")
        summary_path = workflow.save_workflow_summary()
        workflow.print_workflow_summary()

        result = {
            "workflow_completed": True,
            "workflow_directory": str(workflow.workflow_dir),
            "final_data_path": final_data_path,
            "summary_path": summary_path,
            "load_result": load_result,
            "extraction_result": extraction_result,
            "process_keyword_result": process_keyword_result,
            "separation_result": separation_step,
            "cleaning_result": cleaning_result,
            "no_sql_removal_result": no_sql_removal_result,
            "fix_result": fix_result,
            "merge_result": merge_step
        }

        print("\nâœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {result['workflow_directory']}")
        print(f"ğŸ“„ æœ€ç»ˆæ•°æ®: {result['final_data_path']}")
        print(f"ğŸ“‹ æ‘˜è¦æ–‡ä»¶: {result['summary_path']}")
        
        return result
        
    except Exception as e:
        logging.error(f"å…³é”®è¯ä¼˜å…ˆå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        raise


def run_resume_workflow(args):
    """è¿è¡Œresumeå·¥ä½œæµ"""
    print(f"ğŸ”„ ä»å·¥ä½œæµç›®å½• {args.resume} ç»§ç»­æ‰§è¡Œ")
    
    import tempfile
    import shutil
    temp_dir = tempfile.mkdtemp(prefix="temp_workflow_")
    
    try:
        # åˆ›å»ºå·¥ä½œæµç®¡ç†å™¨ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•é¿å…åˆ›å»ºä¸éœ€è¦çš„ç›®å½•
        workflow = WorkflowManager(base_output_dir=temp_dir)
        
        if not workflow.load_from_existing_workflow(args.resume):
            print(f"âŒ æ— æ³•ä»å·¥ä½œæµç›®å½•åŠ è½½çŠ¶æ€: {args.resume}")
            return None
        
        print(f"âœ… æˆåŠŸåŠ è½½å·¥ä½œæµçŠ¶æ€")
        
        # å¦‚æœæ˜¯æµ‹è¯•æ¨¡å¼ï¼ŒéšæœºæŠ½æ ·æ•°æ®
        if args.test:
            print("ğŸ§ª æµ‹è¯•æ¨¡å¼å¼€å¯ï¼ŒéšæœºæŠ½å–20æ¡æ•°æ®è¿›è¡Œå¤„ç†ã€‚")
            logging.info("ğŸ§ª æµ‹è¯•æ¨¡å¼å¼€å¯ï¼ŒéšæœºæŠ½å–20æ¡æ•°æ®è¿›è¡Œå¤„ç†ã€‚")
            if workflow.current_data and len(workflow.current_data) > 20:
                workflow.current_data = random.sample(workflow.current_data, 20)
                logging.info(f"æ•°æ®å·²é‡‡æ ·ï¼Œå‰©ä½™ {len(workflow.current_data)} æ¡è®°å½•ã€‚")

        # å¦‚æœæŒ‡å®šäº†æ­¥éª¤ï¼Œä»è¯¥æ­¥éª¤å¼€å§‹æ‰§è¡Œ
        if args.from_step:
            print(f"ğŸ¯ ä»æ­¥éª¤ '{args.from_step}' å¼€å§‹æ‰§è¡Œ")
            
            # å‡†å¤‡æ­¥éª¤å‚æ•°
            step_kwargs = {}
            if args.from_step == 'remove_no_sql_records':
                step_kwargs['reanalyze_no_sql'] = args.reanalyze_no_sql
            elif args.from_step == 'redundant_sql_validation':
                step_kwargs['apply_fix'] = args.apply_fix
            elif args.from_step == 'keyword_extraction':
                step_kwargs['keywords'] = args.keywords
            
            try:
                # æ‰§è¡Œå•ä¸ªæ­¥éª¤
                result = workflow.resume_from_step(args.from_step, **step_kwargs)
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€æ­¥ï¼Œç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤
                if args.from_step != 'export_final_data':
                    print("ğŸ”„ ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤...")
                    
                    # å®šä¹‰æ­¥éª¤é¡ºåº
                    step_order = [
                        'remove_no_sql_records',
                        'redundant_sql_validation', 
                        'export_final_data'
                    ]
                    
                    # æ‰¾åˆ°å½“å‰æ­¥éª¤çš„ä½ç½®
                    current_index = step_order.index(args.from_step)
                    
                    # æ‰§è¡Œåç»­æ­¥éª¤
                    for next_step in step_order[current_index + 1:]:
                        print(f"ğŸ”„ æ‰§è¡Œæ­¥éª¤: {next_step}")
                        
                        next_kwargs = {}
                        if next_step == 'remove_no_sql_records':
                            next_kwargs['reanalyze_no_sql'] = args.reanalyze_no_sql
                        elif next_step == 'redundant_sql_validation':
                            next_kwargs['apply_fix'] = args.apply_fix
                        
                        result = workflow.resume_from_step(next_step, **next_kwargs)
                
                print("\nâœ… Resumeå·¥ä½œæµæ‰§è¡ŒæˆåŠŸ!")
                print(f"ğŸ“ å·¥ä½œæµç›®å½•: {workflow.workflow_dir}")
                
                if isinstance(result, dict) and 'final_data_path' in result:
                    print(f"ğŸ“„ æœ€ç»ˆæ•°æ®: {result['final_data_path']}")
                    print(f"ğŸ“‹ æ‘˜è¦æ–‡ä»¶: {result['summary_path']}")
                
                return result
                
            except Exception as e:
                print(f"âŒ Resumeå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return None
        else:
            print("âš ï¸ æœªæŒ‡å®š--from-stepå‚æ•°ï¼Œè¯·æŒ‡å®šè¦ä»å“ªä¸ªæ­¥éª¤å¼€å§‹æ‰§è¡Œ")
            print("å¯ç”¨æ­¥éª¤: remove_no_sql_records, redundant_sql_validation, sql_cleaning, keyword_extraction, export_final_data")
            return None
            
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        try:
            shutil.rmtree(temp_dir)
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    try:
        if args.resume:
            # Resumeæ¨¡å¼
            result = run_resume_workflow(args)
        else:
            # æ–°å·¥ä½œæµæ¨¡å¼
            result = run_new_workflow(args)
        
        if result:
            # æ˜¾ç¤ºç»“æœæ‘˜è¦
            if 'extraction_result' in result:
                ext_res = result['extraction_result']
                print("\nğŸ”‘ å…³é”®è¯æå–ç»“æœ:")
                print(f"   ğŸ“Š è¾“å…¥è®°å½•: {ext_res.get('input_records', 0):,}")
                print(f"   ğŸ¯ æå–è®°å½•: {ext_res.get('extracted_records', 0):,}")
                print(f"   ğŸ“ˆ æå–ç‡: {ext_res.get('extraction_rate', 0.0):.2f}%")

            if 'cleaning_result' in result:
                clean_res = result['cleaning_result']
                print("\nğŸ§¹ SQL æ¸…æ´—ç»“æœ:")
                print(f"   ğŸ“Š è¾“å…¥è®°å½•: {clean_res.get('input_records', 0):,}")
                print(f"   ğŸ“Š è¾“å‡ºè®°å½•: {clean_res.get('output_records', 0):,}")
                print(f"   ğŸ—‘ï¸  ç§»é™¤æ— æ•ˆ SQL: {clean_res.get('invalid_sql_removed', 0):,}")
                print(f"   âœï¸  ä¿®æ”¹è®°å½•: {clean_res.get('records_modified', 0):,}")
            
            return 0
        else:
            return 1

    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main()) 