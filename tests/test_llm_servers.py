#!/usr/bin/env python3
"""LLMæœåŠ¡å™¨æµ‹è¯•"""
import pytest
import asyncio
import aiohttp
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = str(Path(__file__).parent.parent)
sys.path.insert(0, project_root)

from openai import OpenAI
from config.llm.llm_config import get_llm_config, ServerConfig
from utils.llm_client import LLMClient
from utils.format_validators import validate_json_format


class TestLLMServers:
    """LLMæœåŠ¡å™¨æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.config = get_llm_config()
    
    def test_yaml_config_loading(self):
        """æµ‹è¯•YAMLé…ç½®æ–‡ä»¶åŠ è½½"""
        print(f"é…ç½®æ–‡ä»¶è·¯å¾„: {self.config.config_file}")
        servers = self.config.list_servers()
        print(f"åŠ è½½çš„æœåŠ¡å™¨: {servers}")
        
        defaults = self.config.get_defaults()
        print(f"é»˜è®¤é…ç½®: {defaults}")
    
    def test_server_configs(self):
        """æµ‹è¯•æœåŠ¡å™¨é…ç½®"""
        # æµ‹è¯•v3é…ç½®
        v3_config = self.config.get_server_config("v3")
        print(f"V3é…ç½®: {v3_config.host}:{v3_config.port}, æ¨¡å‹: {v3_config.model_name}")
        
        # æµ‹è¯•r1é…ç½®
        r1_config = self.config.get_server_config("r1")
        print(f"R1é…ç½®: {r1_config.host}:{r1_config.port}, æ¨¡å‹: {r1_config.model_name}")
        
        # æµ‹è¯•å®Œæ•´URL
        print(f"V3å®Œæ•´URL: {v3_config.full_url}")
        print(f"R1å®Œæ•´URL: {r1_config.full_url}")
        print(f"V3èŠå¤©API URL: {v3_config.chat_completions_url}")
        print(f"R1èŠå¤©API URL: {r1_config.chat_completions_url}")
    
    def test_openai_client_config(self):
        """æµ‹è¯•OpenAIå®¢æˆ·ç«¯é…ç½®"""
        v3_openai_config = self.config.get_openai_client_config("v3")
        print(f"V3 OpenAIé…ç½®: {v3_openai_config}")
        
        r1_openai_config = self.config.get_openai_client_config("r1")
        print(f"R1 OpenAIé…ç½®: {r1_openai_config}")
    
    def test_llm_client_creation(self):
        """æµ‹è¯•LLMå®¢æˆ·ç«¯åˆ›å»º"""
        v3_client = LLMClient("v3")
        print(f"V3å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {v3_client.server_name}")
        
        r1_client = LLMClient("r1")
        print(f"R1å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ: {r1_client.server_name}")
    
    async def test_v3_sync_api(self):
        """æµ‹è¯•V3åŒæ­¥APIè°ƒç”¨"""
        try:
            client = LLMClient("v3")
            async with aiohttp.ClientSession() as session:
                response = await client.call_async_with_format_validation(
                    session,
                    "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªV3åŒæ­¥æµ‹è¯•ã€‚", 
                    validator=validate_json_format,
                    max_tokens=100
                )
            if response:
                print(f"âœ… V3åŒæ­¥APIè°ƒç”¨æˆåŠŸ: {response}")
            else:
                print("âŒ V3åŒæ­¥APIè°ƒç”¨å¤±è´¥: ç©ºå“åº”")
        except Exception as e:
            print(f"âŒ V3åŒæ­¥APIè°ƒç”¨å¤±è´¥: {str(e)}")
            pytest.skip(f"V3åŒæ­¥APIä¸å¯ç”¨: {str(e)}")
    
    async def test_r1_sync_api(self):
        """æµ‹è¯•R1åŒæ­¥APIè°ƒç”¨"""
        try:
            client = LLMClient("r1")
            async with aiohttp.ClientSession() as session:
                response = await client.call_async_with_format_validation(
                    session,
                    "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªR1åŒæ­¥æµ‹è¯•ã€‚", 
                    validator=validate_json_format,
                    max_tokens=100
                )
            if response:
                print(f"âœ… R1åŒæ­¥APIè°ƒç”¨æˆåŠŸ: {response}")
            else:
                print("âŒ R1åŒæ­¥APIè°ƒç”¨å¤±è´¥: ç©ºå“åº”")
        except Exception as e:
            print(f"âŒ R1åŒæ­¥APIè°ƒç”¨å¤±è´¥: {str(e)}")
            pytest.skip(f"R1åŒæ­¥APIä¸å¯ç”¨: {str(e)}")
    
    async def test_v3_openai_api(self):
        """æµ‹è¯•V3 OpenAIåº“è°ƒç”¨"""
        try:
            client = LLMClient("v3")
            async with aiohttp.ClientSession() as session:
                response = await client.call_async_with_format_validation(
                    session,
                    "Hello, this is a V3 OpenAI test.", 
                    validator=validate_json_format,
                    max_tokens=50
                )
            if response:
                print(f"âœ… V3 OpenAIè°ƒç”¨æˆåŠŸ: {response}")
            else:
                print("âŒ V3 OpenAIè°ƒç”¨å¤±è´¥: ç©ºå“åº”")
        except Exception as e:
            print(f"âŒ V3 OpenAIè°ƒç”¨å¤±è´¥: {str(e)}")
            pytest.skip(f"V3 OpenAIä¸å¯ç”¨: {str(e)}")
    
    async def test_r1_openai_api(self):
        """æµ‹è¯•R1 OpenAIåº“è°ƒç”¨"""
        try:
            client = LLMClient("r1")
            async with aiohttp.ClientSession() as session:
                response = await client.call_async_with_format_validation(
                    session,
                    "Hello, this is a R1 OpenAI test.", 
                    validator=validate_json_format,
                    max_tokens=50
                )
            if response:
                print(f"âœ… R1 OpenAIè°ƒç”¨æˆåŠŸ: {response}")
            else:
                print("âŒ R1 OpenAIè°ƒç”¨å¤±è´¥: ç©ºå“åº”")
        except Exception as e:
            print(f"âŒ R1 OpenAIè°ƒç”¨å¤±è´¥: {str(e)}")
            pytest.skip(f"R1 OpenAIä¸å¯ç”¨: {str(e)}")
    
    async def async_test_v3_api(self):
        """å¼‚æ­¥æµ‹è¯•V3 API"""
        async with aiohttp.ClientSession() as session:
            client = LLMClient("v3")
            response = await client.call_async_with_format_validation(
                session, 
                "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªV3å¼‚æ­¥æµ‹è¯•ã€‚", 
                validator=validate_json_format,
                max_tokens=100
            )
            if response:
                print(f"âœ… V3å¼‚æ­¥APIè°ƒç”¨æˆåŠŸ: {response}")
            else:
                print("âŒ V3å¼‚æ­¥APIè°ƒç”¨å¤±è´¥: ç©ºå“åº”")
    
    async def async_test_r1_api(self):
        """å¼‚æ­¥æµ‹è¯•R1 API"""
        async with aiohttp.ClientSession() as session:
            client = LLMClient("r1")
            response = await client.call_async_with_format_validation(
                session, 
                "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªR1å¼‚æ­¥æµ‹è¯•ã€‚", 
                validator=validate_json_format,
                max_tokens=100
            )
            if response:
                print(f"âœ… R1å¼‚æ­¥APIè°ƒç”¨æˆåŠŸ: {response}")
            else:
                print("âŒ R1å¼‚æ­¥APIè°ƒç”¨å¤±è´¥: ç©ºå“åº”")
    
    def test_v3_async_api(self):
        """æµ‹è¯•V3å¼‚æ­¥APIè°ƒç”¨ï¼ˆåŒ…è£…å™¨ï¼‰"""
        try:
            asyncio.run(self.async_test_v3_api())
        except Exception as e:
            print(f"âŒ V3å¼‚æ­¥APIè°ƒç”¨å¤±è´¥: {str(e)}")
            pytest.skip(f"V3å¼‚æ­¥APIä¸å¯ç”¨: {str(e)}")
    
    def test_r1_async_api(self):
        """æµ‹è¯•R1å¼‚æ­¥APIè°ƒç”¨ï¼ˆåŒ…è£…å™¨ï¼‰"""
        try:
            asyncio.run(self.async_test_r1_api())
        except Exception as e:
            print(f"âŒ R1å¼‚æ­¥APIè°ƒç”¨å¤±è´¥: {str(e)}")
            pytest.skip(f"R1å¼‚æ­¥APIä¸å¯ç”¨: {str(e)}")
    

    
    def test_list_servers(self):
        """æµ‹è¯•åˆ—å‡ºæ‰€æœ‰æœåŠ¡å™¨"""
        servers = self.config.list_servers()
        print(f"å¯ç”¨æœåŠ¡å™¨: {servers}")


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    test_instance = TestLLMServers()
    
    print("ğŸ”§ æµ‹è¯•YAMLé…ç½®åŠ è½½...")
    test_instance.test_yaml_config_loading()
    print("âœ… YAMLé…ç½®åŠ è½½æµ‹è¯•é€šè¿‡")
    
    print("\nğŸ”§ æµ‹è¯•æœåŠ¡å™¨é…ç½®...")
    test_instance.test_server_configs()
    print("âœ… æœåŠ¡å™¨é…ç½®æµ‹è¯•é€šè¿‡")
    
    print("\nğŸ”§ æµ‹è¯•OpenAIå®¢æˆ·ç«¯é…ç½®...")
    test_instance.test_openai_client_config()
    print("âœ… OpenAIå®¢æˆ·ç«¯é…ç½®æµ‹è¯•é€šè¿‡")
    
    print("\nğŸ”§ æµ‹è¯•LLMå®¢æˆ·ç«¯åˆ›å»º...")
    test_instance.test_llm_client_creation()
    print("âœ… LLMå®¢æˆ·ç«¯åˆ›å»ºæµ‹è¯•é€šè¿‡")
    

    
    print("\nğŸ”§ æµ‹è¯•æœåŠ¡å™¨åˆ—è¡¨...")
    test_instance.test_list_servers()
    print("âœ… æœåŠ¡å™¨åˆ—è¡¨æµ‹è¯•é€šè¿‡")
    
    print("\nğŸ”— æµ‹è¯•V3åŒæ­¥API...")
    asyncio.run(test_instance.test_v3_sync_api())
    
    print("\nğŸ”— æµ‹è¯•R1åŒæ­¥API...")
    asyncio.run(test_instance.test_r1_sync_api())
    
    print("\nğŸŒ æµ‹è¯•V3 OpenAIåº“...")
    asyncio.run(test_instance.test_v3_openai_api())
    
    print("\nğŸŒ æµ‹è¯•R1 OpenAIåº“...")
    asyncio.run(test_instance.test_r1_openai_api())
    
    print("\nâš¡ æµ‹è¯•V3å¼‚æ­¥API...")
    test_instance.test_v3_async_api()
    
    print("\nâš¡ æµ‹è¯•R1å¼‚æ­¥API...")
    test_instance.test_r1_async_api()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼") 