"""
æ ¸å¿ƒéªŒè¯å™¨æ¨¡å—
"""
import asyncio
import json
import logging
import sys
from pathlib import Path

import aiohttp
import yaml
from tqdm import tqdm

from utils.llm_client import LLMClientManager
from config.validation.validation_prompts import (
    ANALYSIS_PROMPT_TEMPLATE,
    VERIFICATION_PROMPT_TEMPLATE,
    FORMATTING_PROMPT_TEMPLATE,
)

logger = logging.getLogger(__name__)


class RerunValidator:
    """å°è£…é‡æ–°è¿è¡Œåˆ†æå’ŒéªŒè¯é€»è¾‘çš„ç±»"""

    def __init__(self, config_path="config/rerun_config.yaml", custom_output_dir=None):
        """
        åˆå§‹åŒ–éªŒè¯å™¨ã€‚
        Args:
            config_path: é…ç½®æ–‡ä»¶çš„è·¯å¾„ã€‚
            custom_output_dir: è‡ªå®šä¹‰è¾“å‡ºç›®å½•ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„output_dir
        """
        self.config = self._load_config(config_path)
        self.client_manager = LLMClientManager()
        self._setup_logging()
        
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰è¾“å‡ºç›®å½•ï¼Œåˆ™è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®
        if custom_output_dir:
            self.config['output_dir'] = str(custom_output_dir)
            logger.info(f"ä½¿ç”¨è‡ªå®šä¹‰è¾“å‡ºç›®å½•: {custom_output_dir}")
        
        # æ·»åŠ è¯¦ç»†ç»“æœæ”¶é›†å™¨
        self.detailed_results = []
        self.detailed_results_lock = asyncio.Lock()

    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½YAMLé…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°: {config_path}")
            sys.exit(1)
        except yaml.YAMLError as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶YAMLæ ¼å¼é”™è¯¯: {config_path} - {e}")
            sys.exit(1)

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—è®°å½•å™¨"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

    def _format_rerun_prompt(self, record: dict) -> str:
        """æ ¼å¼åŒ–ç”¨äºé‡æ–°åˆ†æçš„æç¤ºè¯ï¼ˆæ—§é€»è¾‘ï¼‰"""
        code_value = record.get('orm_code', '')
        if not code_value:
            if record.get('code_meta_data') and isinstance(record['code_meta_data'], list) and record['code_meta_data']:
                code_value = record['code_meta_data'][0].get('code_value', '')

        function_name = record.get('function_name', 'N/A')
        caller = record.get('caller', 'N/A')
        code_meta_data_str = json.dumps(record.get('code_meta_data', []), ensure_ascii=False, indent=2)
        callee = "N/A"
        
        return ANALYSIS_PROMPT_TEMPLATE.format(
            function_name=function_name,
            code_value=code_value,
            caller=caller,
            code_meta_data_str=code_meta_data_str,
            sql_pattern_cnt=record.get('sql_pattern_cnt', 0)
        )

    async def _run_single_analysis(self, semaphore: asyncio.Semaphore, record: dict, pbar: tqdm, output_file, file_lock, session) -> dict:
        """å¯¹å•ä¸ªè®°å½•è¿›è¡Œåˆ†æï¼Œå¹¶ç«‹å³å°†ç»“æœå†™å…¥æ–‡ä»¶"""
        async with semaphore:
            prompt = self._format_rerun_prompt(record)
            client = self.client_manager.get_client(self.config['server'])
            
            try:
                # ä½¿ç”¨å¸¦é‡è¯•æœºåˆ¶çš„call_asyncæ–¹æ³•
                result_content = await client.call_async(
                    session, 
                    prompt, 
                    max_tokens=4096, 
                    temperature=0.0,
                    max_retries=5,
                    retry_delay=1.0
                )
                
                try:
                    new_sql = json.loads(result_content)
                    json_parse_success = True
                    json_parse_error = None
                except (json.JSONDecodeError, TypeError) as e:
                    new_sql = result_content
                    json_parse_success = False
                    json_parse_error = str(e)
                
                analysis_result = {
                    "function_name": record["function_name"],
                    "source_file": record["source_file"],
                    "original_orm_code": record.get("orm_code", ""),
                    "new_sql_analysis_result": new_sql,
                    # æ–°å¢ï¼šæ¨¡å‹å›å¤è¯¦ç»†ä¿¡æ¯
                    "model_response": {
                        "raw_content": result_content,
                        "content_length": len(result_content),
                        "server": self.config.get('server', 'unknown'),
                        "json_parse_success": json_parse_success,
                        "json_parse_error": json_parse_error
                    },
                    # æ–°å¢ï¼šæç¤ºè¯ä¿¡æ¯
                    "prompt_info": {
                        "prompt_content": prompt,
                        "prompt_length": len(prompt),
                        "prompt_type": "single_stage_analysis"
                    },
                    # æ–°å¢ï¼šè¾“å…¥è®°å½•å…ƒæ•°æ®
                    "input_metadata": {
                        "caller": record.get('caller', ''),
                        "sql_pattern_cnt": record.get('sql_pattern_cnt', 0),
                        "code_meta_data_count": len(record.get('code_meta_data', []))
                    }
                }
            except Exception as e:
                logger.error(f"åˆ†æå¤±è´¥: {record['function_name']} - {e}")
                analysis_result = {
                    "function_name": record["function_name"],
                    "source_file": record["source_file"],
                    "error": str(e),
                    "error_type": type(e).__name__,
                    # å³ä½¿å‡ºé”™ä¹Ÿä¿ç•™æç¤ºè¯ä¿¡æ¯
                    "prompt_info": {
                        "prompt_content": prompt,
                        "prompt_length": len(prompt),
                        "prompt_type": "single_stage_analysis"
                    }
                }

            async with file_lock:
                output_file.write(json.dumps(analysis_result, ensure_ascii=False) + '\n')
                output_file.flush()

            pbar.update(1)
            return analysis_result

    def _get_common_prompt_fields(self, record: dict) -> dict:
        """ä»è®°å½•ä¸­æå–ç”¨äºæ ¼å¼åŒ–æç¤ºè¯çš„é€šç”¨å­—æ®µ"""
        code_value = record.get('orm_code', '')
        if not code_value and record.get('code_meta_data'):
             if isinstance(record['code_meta_data'], list) and record['code_meta_data']:
                code_value = record['code_meta_data'][0].get('code_value', '')

        return {
            "function_name": record.get('function_name', 'N/A'),
            "code_value": code_value,
            "code_meta_data_str": json.dumps(record.get('code_meta_data', []), ensure_ascii=False, indent=2),
            "caller": record.get('caller', 'N/A'),
            "sql_pattern_cnt": record.get('sql_pattern_cnt', 0)
        }

    def generate_precheck_prompts(self, record: dict, analysis_result: str = "") -> dict:
        """
        ä¸ºç»™å®šçš„è®°å½•ç”Ÿæˆä¸‰é˜¶æ®µçš„é¢„æ£€æŸ¥æç¤ºè¯ã€‚
        
        Args:
            record: éœ€è¦åˆ†æçš„æ•°æ®è®°å½•ã€‚
            analysis_result: (å¯é€‰) ç¬¬äºŒé˜¶æ®µéªŒè¯æ—¶éœ€è¦çš„å‰ä¸€é˜¶æ®µåˆ†æç»“æœã€‚

        Returns:
            ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªé˜¶æ®µæç¤ºè¯çš„å­—å…¸ã€‚
        """
        common_fields = self._get_common_prompt_fields(record)

        prompt1 = ANALYSIS_PROMPT_TEMPLATE.format(**common_fields)
        
        prompt2 = VERIFICATION_PROMPT_TEMPLATE.format(
            analysis_result=analysis_result,
            function_definition=record.get('orm_code', ''),
            code_chain='',  # å¦‚éœ€å¯å¡«å……è°ƒç”¨é“¾ä¸Šä¸‹æ–‡
            sql_statement=analysis_result,
            **common_fields
        )

        # ç¬¬ä¸‰é˜¶æ®µçš„è¾“å…¥æ˜¯ç¬¬äºŒé˜¶æ®µçš„è¾“å‡ºï¼Œè¿™é‡Œæˆ‘ä»¬åªå‡†å¤‡æ¨¡æ¿
        # å®é™…ä½¿ç”¨æ—¶ï¼Œéœ€è¦ç”¨ç¬¬äºŒé˜¶æ®µçš„LLMè¾“å‡ºæ¥å¡«å…… {analysis_to_format}
        prompt3_template = FORMATTING_PROMPT_TEMPLATE

        return {
            "analysis_prompt": prompt1,
            "verification_prompt": prompt2,
            "formatting_prompt_template": prompt3_template
        }

    async def run_three_stage_analysis(self, record: dict, save_detailed_results: bool = True) -> dict:
        """
        æ‰§è¡Œä¸‰æ®µå¼åˆ†ææµç¨‹å¹¶è§£æJSONç»“æœ
        
        Args:
            record: éœ€è¦åˆ†æçš„æ•°æ®è®°å½•
            save_detailed_results: æ˜¯å¦ä¿å­˜è¯¦ç»†çš„æ¨¡å‹å›å¤ç»“æœåˆ°æ–‡ä»¶
            
        Returns:
            åŒ…å«å„é˜¶æ®µç»“æœå’Œè§£æåJSONçš„å­—å…¸
        """
        try:
            # è·å–LLMå®¢æˆ·ç«¯
            client = self.client_manager.get_client(self.config['server'])
            
            async with aiohttp.ClientSession() as session:
                # ç¬¬ä¸€é˜¶æ®µï¼šåˆ†æ
                stage_prompts = self.generate_precheck_prompts(record)
                analysis_result = await client.call_async(
                    session,
                    stage_prompts['analysis_prompt'], 
                    max_tokens=4096, 
                    temperature=0.0,
                    max_retries=5,
                    retry_delay=1.0
                )
                
                if not analysis_result:
                    logger.error("âŒ ç¬¬ä¸€é˜¶æ®µè¿”å›ç©ºç»“æœ")
                    return {
                        "analysis_result": "",
                        "verification_result": "",
                        "final_result": "",
                        "parsed_json": None,
                        "success": False,
                        "error": "ç¬¬ä¸€é˜¶æ®µLLMè°ƒç”¨å¤±è´¥"
                    }
                
                # ç¬¬äºŒé˜¶æ®µï¼šéªŒè¯
                verification_prompts = self.generate_precheck_prompts(record, analysis_result)
                verification_result = await client.call_async(
                    session,
                    verification_prompts['verification_prompt'],
                    max_tokens=4096,
                    temperature=0.0,
                    max_retries=5,
                    retry_delay=1.0
                )
                
                if not verification_result:
                    logger.error("âŒ ç¬¬äºŒé˜¶æ®µè¿”å›ç©ºç»“æœ")
                    return {
                        "analysis_result": analysis_result,
                        "verification_result": "",
                        "final_result": "",
                        "parsed_json": None,
                        "success": False,
                        "error": "ç¬¬äºŒé˜¶æ®µLLMè°ƒç”¨å¤±è´¥"
                    }
                
                # ç¬¬ä¸‰é˜¶æ®µï¼šæ ¼å¼åŒ–
                format_prompt = FORMATTING_PROMPT_TEMPLATE.format(sql_statement=verification_result)
                final_result = await client.call_async(
                    session,
                    format_prompt,
                    max_tokens=4096,
                    temperature=0.0,
                    max_retries=5,
                    retry_delay=1.0
                )
                
                if not final_result:
                    logger.error("âŒ ç¬¬ä¸‰é˜¶æ®µè¿”å›ç©ºç»“æœ")
                    return {
                        "analysis_result": analysis_result,
                        "verification_result": verification_result,
                        "final_result": "",
                        "parsed_json": None,
                        "success": False,
                        "error": "ç¬¬ä¸‰é˜¶æ®µLLMè°ƒç”¨å¤±è´¥"
                    }
                
                # å°è¯•è§£æJSON
                parsed_json = None
                try:
                    parsed_json = json.loads(final_result)
                except (json.JSONDecodeError, TypeError) as e:
                    # å°è¯•æå–JSONéƒ¨åˆ†ï¼ˆå¯èƒ½åŒ…å«åœ¨ä»£ç å—ä¸­ï¼‰
                    import re
                    # ä¿®å¤æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ­£ç¡®å¤„ç†æ¢è¡Œç¬¦å’ŒåµŒå¥—ç»“æ„
                    json_match = re.search(r'```json\s*(.*?)\s*```', final_result, re.DOTALL)
                    if json_match:
                        json_content = json_match.group(1).strip()
                        try:
                            parsed_json = json.loads(json_content)
                        except (json.JSONDecodeError, TypeError):
                            logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                            logger.warning(f"ğŸ” è§£æå¤±è´¥çš„å†…å®¹: {repr(final_result[:500])}...")
                    else:
                        logger.warning(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                        logger.warning(f"ğŸ” è§£æå¤±è´¥çš„å†…å®¹: {repr(final_result[:500])}...")
                
                # æ„å»ºè¯¦ç»†çš„ç»“æœä¿¡æ¯
                detailed_result = {
                    # åŸºæœ¬ç»“æœä¿¡æ¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
                    "analysis_result": analysis_result,
                    "verification_result": verification_result,
                    "final_result": final_result,
                    "parsed_json": parsed_json,
                    "success": True,
                    
                    # æ–°å¢ï¼šè¯¦ç»†çš„é˜¶æ®µä¿¡æ¯
                    "stage_details": {
                        "stage1_analysis": {
                            "prompt": stage_prompts['analysis_prompt'],
                            "prompt_length": len(stage_prompts['analysis_prompt']),
                            "raw_response": analysis_result,
                            "response_length": len(analysis_result),
                            "stage_type": "ORMä»£ç åˆ†æ"
                        },
                        "stage2_verification": {
                            "prompt": verification_prompts['verification_prompt'],
                            "prompt_length": len(verification_prompts['verification_prompt']),
                            "raw_response": verification_result,
                            "response_length": len(verification_result),
                            "stage_type": "SQLè¯­å¥éªŒè¯"
                        },
                        "stage3_formatting": {
                            "prompt": format_prompt,
                            "prompt_length": len(format_prompt),
                            "raw_response": final_result,
                            "response_length": len(final_result),
                            "stage_type": "ç»“æœæ ¼å¼åŒ–"
                        }
                    },
                    
                    # æ–°å¢ï¼šè¾“å…¥è®°å½•ä¿¡æ¯
                    "input_record": {
                        "function_name": record.get('function_name', ''),
                        "source_file": record.get('source_file', ''),
                        "caller": record.get('caller', ''),
                        "sql_pattern_cnt": record.get('sql_pattern_cnt', 0),
                        "orm_code_length": len(record.get('orm_code', '')),
                        "code_meta_data_count": len(record.get('code_meta_data', []))
                    },
                    
                    # æ–°å¢ï¼šå¤„ç†å…ƒæ•°æ®
                    "processing_metadata": {
                        "server": self.config.get('server', 'unknown'),
                        "max_tokens": 4096,
                        "temperature": 0.0,
                                    "retry_config": {
                "max_retries": 5,
                "retry_delay": 1.0
                        },
                        "json_parsing": {
                            "final_parse_success": parsed_json is not None,
                            "final_parse_error": None if parsed_json is not None else "è§£æå¤±è´¥"
                        }
                    }
                }
                
                # å¦‚æœéœ€è¦ä¿å­˜è¯¦ç»†ç»“æœåˆ°æ–‡ä»¶
                if save_detailed_results:
                    await self._collect_detailed_results(record, detailed_result)
                
                return detailed_result
            
        except Exception as e:
            logger.error(f"âŒ ä¸‰æ®µå¼åˆ†ææµç¨‹å¼‚å¸¸: {e}")
            return {
                "analysis_result": "",
                "verification_result": "",
                "final_result": "",
                "parsed_json": None,
                "success": False,
                "error": f"æµç¨‹å¼‚å¸¸: {str(e)}"
            }

    async def _collect_detailed_results(self, record: dict, detailed_result: dict):
        """æ”¶é›†è¯¦ç»†çš„ä¸‰æ®µå¼åˆ†æç»“æœ"""
        async with self.detailed_results_lock:
            self.detailed_results.append(detailed_result)
            logger.debug(f"æ”¶é›†åˆ°è¯¦ç»†ç»“æœ: {record['function_name']}")

    async def save_all_detailed_results(self):
        """ä¿å­˜æ‰€æœ‰æ”¶é›†çš„è¯¦ç»†ç»“æœåˆ°å•ä¸ªJSONæ–‡ä»¶"""
        try:
            if not self.detailed_results:
                logger.info("æ²¡æœ‰è¯¦ç»†ç»“æœéœ€è¦ä¿å­˜")
                return
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path(self.config.get('output_dir', 'validator_output'))
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜åˆ°å•ä¸ªJSONæ–‡ä»¶
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"detailed_analysis_results_{timestamp}.json"
            filepath = output_dir / filename
            
            # æ„å»ºç»Ÿä¸€çš„ç»“æœç»“æ„
            summary = {
                "metadata": {
                    "total_records": len(self.detailed_results),
                    "timestamp": timestamp,
                    "server": self.config.get('server', 'unknown'),
                    "analysis_type": "three_stage_analysis"
                },
                "results": self.detailed_results
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“ æ‰€æœ‰è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
            logger.info(f"   æ€»å…±ä¿å­˜äº† {len(self.detailed_results)} æ¡è¯¦ç»†åˆ†æç»“æœ")
            return str(filepath)
            
        except Exception as e:
            logger.error(f"ä¿å­˜è¯¦ç»†ç»“æœå¤±è´¥: {e}")
            return None

    async def run_rerun_analysis(self):
        """æ‰§è¡Œé‡æ–°åˆ†æçš„å®Œæ•´æµç¨‹"""
        
        try:
            with open(self.config['input_file'], 'r', encoding='utf-8') as f:
                all_data = json.load(f)
        except FileNotFoundError:
            logger.error(f"âŒ è¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ°: {self.config['input_file']}")
            return
        except json.JSONDecodeError:
            logger.error(f"âŒ è¾“å…¥æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {self.config['input_file']}")
            return

        records_to_process = [r for r in all_data if r.get("sql_statement_list") == "<NO SQL GENERATE>"]
        
        if not records_to_process:
            logger.warning("æœªæ‰¾åˆ°éœ€è¦é‡æ–°åˆ†æçš„è®°å½• (<NO SQL GENERATE>)ã€‚")
            return
        
        output_dir = Path(self.config['output_dir'])
        output_dir.mkdir(parents=True, exist_ok=True)
        output_path = output_dir / self.config['output_filename']
        
        semaphore = asyncio.Semaphore(self.config['concurrency'])
        file_lock = asyncio.Lock()
        
        results = []
        async with aiohttp.ClientSession() as session:
            with open(output_path, 'w', encoding='utf-8') as f:
                with tqdm(total=len(records_to_process), desc="é‡æ–°åˆ†æè¿›åº¦") as pbar:
                    tasks = [
                        self._run_single_analysis(semaphore, record, pbar, f, file_lock, session) 
                        for record in records_to_process
                    ]
                    results = await asyncio.gather(*tasks)

        self._print_summary_report(results, records_to_process, output_path)

    def _print_summary_report(self, results: list, records_to_process: list, output_path: Path):
        """æ‰“å°æœ€ç»ˆçš„æ€»ç»“æŠ¥å‘Š"""
        successful_results = [r for r in results if "error" not in r]
        failed_results = [r for r in results if "error" in r]
        
        newly_generated_count = 0
        for r in successful_results:
            analysis = r.get("new_sql_analysis_result")
            if isinstance(analysis, list) and analysis:
                first_item = analysis[0]
                if isinstance(first_item, dict):
                    should_gen_val = first_item.get("should_generate_sql")
                    if str(should_gen_val).strip().lower() == 'false':
                        newly_generated_count += 1
        
        print("\n" + "="*50)
        print("ğŸ“Š é‡æ–°åˆ†ææ€»ç»“æŠ¥å‘Š")
        print("="*50)
        print(f"æ€»å¤„ç†è®°å½•æ•°: {len(records_to_process)}")
        print(f"æˆåŠŸåˆ†ææ•°: {len(successful_results)}")
        print(f"å¤±è´¥åˆ†ææ•°: {len(failed_results)}")
        print("-" * 50)
        print(f"ğŸ‰ æ–°ç”ŸæˆSQLçš„è®°å½•æ•°: {newly_generated_count}")
        print(f"ä»æœªç”ŸæˆSQLçš„è®°å½•æ•°: {len(successful_results) - newly_generated_count}")
        print("="*50)
        if failed_results:
            print("\nå¤±è´¥çš„è®°å½• (å‰5æ¡):")
            for failed in failed_results[:5]:
                print(f"  - {failed['function_name']}: {failed['error']}") 